{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "By using a complete loop, repeat the previous steps multiple times to achieve the final result.\n",
    "Ensure that the recursion correctly passes each step's result into the recursive result.\n",
    "The main idea of writing this loop is:\n",
    "Assume that an initial API call has been made to preliminarily classify the results in the dataset, resulting in an initial classification.\n",
    "Then, use the parsing function to store this initial classification result in a dictionary (storing the classification results of different states as key-value pairs, with keys as state types and values as classified species results).\n",
    "Recursively process each key-value pair, storing each part's results in results, then use different keys as recursive inputs, and return the recursive results, storing them in result{}, and call them separately."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a749f1dc75e16373"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# First, import all the necessary packages\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T02:13:46.057062Z",
     "start_time": "2024-06-07T02:13:45.591544Z"
    }
   },
   "id": "bc52ac322eb9dbf9",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the required file contents, including the morphological matrix data and the initial parsed data.\n",
    "The initial parsed data refers to the species classification information obtained by the initial API call selecting the initial character and its states, stored as a dictionary after parsing.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4060dd898bc361d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1 species: ['Agriphila', 'Chilo', 'Euchromius', 'Haimbachia']\n",
      "Group 2 species: ['Ancylolomia', 'Calamotropha', 'Catoptria', 'Chrysocrambus', 'Chrysoteuchia', 'Crambus', 'Donacaula', 'Pediasia', 'Platytes', 'Schoenobius', 'Thisanotia']\n",
      "[['Agriphila', 'Chilo', 'Euchromius', 'Haimbachia'], ['Ancylolomia', 'Calamotropha', 'Catoptria', 'Chrysocrambus', 'Chrysoteuchia', 'Crambus', 'Donacaula', 'Pediasia', 'Platytes', 'Schoenobius', 'Thisanotia']]\n",
      "State 1: ['Agriphila', 'Chilo', 'Euchromius', 'Haimbachia'] State 2: ['Ancylolomia', 'Calamotropha', 'Catoptria', 'Chrysocrambus', 'Chrysoteuchia', 'Crambus', 'Donacaula', 'Pediasia', 'Platytes', 'Schoenobius', 'Thisanotia']\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "with open(\"D:/桌面/TEST-KG/nexus fix/matrix_knowledge_graph_22.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    matrix_data = json.load(file)\n",
    "\n",
    "# Parsing the API response for the initial character using the parsing function.\n",
    "initial_classification = {'1': ['Agriphila', 'Chilo', 'Euchromius', 'Haimbachia'], '2': ['Ancylolomia', 'Calamotropha', 'Catoptria', 'Chrysocrambus', 'Chrysoteuchia', 'Crambus', 'Donacaula', 'Pediasia', 'Platytes', 'Schoenobius', 'Thisanotia']}\n",
    "\n",
    "# List to store all values.\n",
    "groups = []\n",
    "\n",
    "# This sets the foundation for subsequent distributed loops. Each key-value pair in the dictionary is stored in a list variable, enabling multiple iterations over these variables to eventually store the results.\n",
    "for state, species_list in initial_classification.items():\n",
    "    groups.append(species_list)\n",
    "\n",
    "# Print the results stored in the list.\n",
    "for i, group in enumerate(groups, 1):\n",
    "    print(f\"Group {i} species:\", group)\n",
    "print(groups)\n",
    "group_1_species = groups[0]\n",
    "group_2_species = groups[1]\n",
    "\n",
    "print(f\"State 1: {group_1_species}\",f\"State 2: {group_2_species}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T02:15:10.794514Z",
     "start_time": "2024-06-07T02:15:10.561053Z"
    }
   },
   "id": "9d7f6349578d5582",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "The loop construction part needs two functions:\n",
    "1. API call part: Create a generic API call applicable to all keys, maintaining consistency in the results for all keys in the groups.\n",
    "2. Loop construction: In the loop traversal function, it's important to call the matrix information stored in each key's subgroup to reduce the API call burden. Repeated API calls for data classification are necessary, so correctly passing input is crucial.\n",
    "Additionally, focus on how to save, store, and parse each API response result. It's best to simply output the final result in the loop.\n",
    "Consider a potential issue: the number of taxa classification results achieved in one go. Currently, the test dataset includes 12 taxa. After initial classification, they are roughly divided into 2, 4, and 6. When there are 6 taxa, errors tend to occur. Therefore, set a conditional statement in the loop: if the number of species in the key exceeds a threshold, use another API call for initial classification, and then proceed with direct classification in the next step. This idea involves dynamic classification selection, where secondary results need to be parsed and passed to the API. Hence, an additional parsing function is required after this conditional call.\n",
    "The current priority is to construct a loop."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23b3e03061a56a5e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# API call function for continued grouping for each subgroup\n",
    "def classify_group(group_species):\n",
    "    group_matrix = {species: matrix_data[species] for species in group_species}\n",
    "    group_matrix_str = json.dumps(group_matrix, ensure_ascii=False)\n",
    "    messages3 = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\":\n",
    "                 \"\"\"\n",
    "                 You are a helpful taxonomist assistant.\\n\n",
    "                 You are skilled at calculating the correct information gain to choose the character that best divides species into even groups based on their states.\\n\n",
    "                 Based on the selected character, classify the species into different groups according to their states.\\n\n",
    "                 For each group with more than two species, continue selecting characters to further classify this group until each group only has one species.\\n\n",
    "                 After multiple classifications, determine the final classification levels and record each classifying character and its state.\\n\n",
    "                 Finally, generate a taxonomic key.\n",
    "                 \"\"\"},\n",
    "            {\"role\": \"system\",\"content\":\n",
    "                \"\"\"\n",
    "                Generate the nested taxonomic key based on the provided morphological matrix. \\n\n",
    "                The process involves selecting a character to classify the species into groups. Repeat this classification within each subgroup until each group contains only one species.\n",
    "                Information gain measures how much the uncertainty in the dataset is reduced after using a character for classification. It helps in selecting characters that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "                Please select the classification character for these group's species based on the morphological matrix and information gain methods.\n",
    "                In the morphological matrix, 'Missing' and 'Not applicable' are invalid states. If a character has invalid states for the group being classified, it should be ignored.\n",
    "                States are represented by numbers. For example, '1 and 2' means multiple states should be treated as a single state type and this multi-state characterization should not be confused with the single states within it (the state of '3' and '2 and 3' is different state, when you choose the character to based on the state to distinguish need to careful handle).The initial character should have no more than three state types.\n",
    "                You need to calculate the information gain for each character and choose the highest information gain result. The higher the information gain result, the greater the contribution of the feature to the classification.\n",
    "                After selecting the initial classification character and categorizing the species based on its state, repeat the process within each subgroup. For each subgroup, select the character with the highest information gain to further classify the species. Continue this process recursively until each group contains only one species.\n",
    "                Now I will show you the morphological matrix. Please provide the classification character and the categorization of species based on its state. Then, continue to classify each subgroup recursively, showing the chosen character and categorization for each subgroup. Please present the result in a structured format, with each step clearly labeled.\n",
    "                please don't show how you analysis and calculate, please show me the final result           \n",
    "            \"\"\"},\n",
    "            {\"role\": \"assistant\",\n",
    "             \"content\": \"\"\"\n",
    "                Understood. I will generate the nested taxonomic key based on the provided morphological matrix. Here is a summary of the steps I will follow:\\n\n",
    "                1. The matrix includes all species and their different states for each character.\\n\n",
    "                2. I will select a character to classify the species into groups and repeat this classification within each subgroup until each group contains only one species.\\n\n",
    "                3. I will use information gain to measure how much the uncertainty in the dataset is reduced after using a feature for classification. This helps in selecting features that minimize the entropy of the subset after classification, leading to better classification results.\\n\n",
    "                4. I will select the classification character for the group's species based on the morphological matrix and information gain methods.\\n\n",
    "                5. In the morphological matrix, 'Missing' and 'Not applicable' are considered invalid states. If a character has invalid states for the group being classified, it will be ignored.\\n\n",
    "                6. States are represented by numbers. For example, '2 and 3' means multiple states should be treated as a single state type, and This multi-state characterization should not be confused with the individual states(like '2', '3') within it (such as '3' and '2 and 3'  is the different state, these are two separate states, when i choose character to based on different state to distinguish the species). The classification character should have no more than three state types.\\n\n",
    "                7. I will use information gain to calculate all character and choose the highest information gain result, The higher the Information Gain result, the greater the contribution of the feature to the classification. \\n\n",
    "                8. The final result will provide only the initial classification character and the categorization of species based on its state. \\n\n",
    "                9. Don't need to show how the process about choose, only need to show the final result as nested structure, and i will store result in #character classify result# block\n",
    "                Please provide the group morphological matrix data so that I can proceed with the classification.\n",
    "             \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here is the group information need to be classify and include the morphological matrix{group_matrix_str}\"}\n",
    "        ]\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages3,\n",
    "            stop=None,\n",
    "            temperature=0,\n",
    "            max_tokens=1000,\n",
    "            n=1)\n",
    "    result = response.choices[0].message.content\n",
    "    print(f\"API response for group {group_species}: {result}\")\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T02:14:14.307974Z",
     "start_time": "2024-06-07T02:14:14.302928Z"
    }
   },
   "id": "883bc1fb4a8f1347",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "After writing the main function for this call, all I needed to implement was to store the final result by using recursion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1459862e51d8b8b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def recursive_classification(groups, final_classification, classification_results):\n",
    "    while groups:  # Continue looping while the groups list is not empty\n",
    "        try:\n",
    "            state, current_group = groups.pop(0)  # Extract the first tuple from groups, containing state identifier and current group of species\n",
    "            print(f\"Processing group with state: {state}, species: {current_group}\")  # Print the current group's state and species for debugging\n",
    "\n",
    "            if len(current_group) == 1:  # If the current group has only one species\n",
    "                final_classification[current_group[0]] = current_group  # Store this single-species group directly in final_classification dictionary\n",
    "            else:\n",
    "                classification_result = classify_group(current_group)  # Call the API function to classify the current group\n",
    "                classification_results[state] = classification_result  # Store the API classification result in classification_results dictionary using state as the key\n",
    "\n",
    "        except Exception as e:  # Catch and handle any exceptions that may occur\n",
    "            print(f\"Error processing group with state: {state}, species: {current_group}\")  # Print the error message and current group's state and species for debugging\n",
    "            print(f\"Exception: {e}\")  # Print the details of the exception\n",
    "            raise e  # Re-raise the exception so that it can be handled by the caller\n",
    "\n",
    "    return final_classification  # Return the final classification result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T02:14:18.961560Z",
     "start_time": "2024-06-07T02:14:18.957241Z"
    }
   },
   "id": "a95e63decd908bc",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a new recursive approach that includes an additional conditional statement to help reduce errors when the API processes a large number of species, thereby improving the accuracy of the final result."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ba9406855035cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This approach aims to generate more accurate classification results by reducing the complexity of API calls to some extent, helping it to perform more accurately.\n",
    "# Suppose this is another API call used when the number of species is too large. The purpose of this part of the API call is to first group a large number of species and then call the relevant functions for further classification (nested classification).\n",
    "def classify_first_group(group_species):\n",
    "    group_matrix = {species: matrix_data[species] for species in group_species}\n",
    "    group_matrix_str = json.dumps(group_matrix, ensure_ascii=False)\n",
    "    messages = \"Here is the group information need to be classify\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        stop=None,\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "        n=1)\n",
    "    result = response.choices[0].message.content\n",
    "    print(f\"API response for group {group_species}: {result}\")\n",
    "    return result\n",
    "\n",
    "# This is a new recursive approach that includes an additional conditional statement to help reduce errors when the API processes a large number of species, thereby improving the accuracy of the final result.\n",
    "def recursive_classification_2(groups, final_classification, classification_results):\n",
    "    while groups:\n",
    "        try:\n",
    "            state, current_group = groups.pop(0)\n",
    "            print(f\"Processing group with state: {state}, species: {current_group}\")  # Debug information\n",
    "\n",
    "            if len(current_group) == 1:\n",
    "                final_classification[current_group[0]] = current_group\n",
    "            else:\n",
    "                if len(current_group) > 6:  # The currently measured result seems to indicate that when the number is around 6, there are some issues. However, it's not conclusive because when I tested this data, there was an additional API call overhead. When studying the results of different groups, I always input the entire matrix, meaning the API had to load the current dataset and select the corresponding species' matrix information from groups[i]. This might consume a lot of additional overhead, causing memory occupation in the API response. Thus, errors occur when there are more than 6 species (the errors are not extremely direct or outrageous but involve misinterpreting '2' and '2 and 3' as a single multi-state feature). Therefore, the API might perform better on single analyses. I think its limit should be around 10 species.\n",
    "                    # Use classify_first_group to subdivide datasets with more than 6 species\n",
    "                    first_classification_result = classify_first_group(current_group)\n",
    "                    classification_results[state] = first_classification_result  # Store initial classification result\n",
    "                    \n",
    "                    # Add the subdivided results to groups for further classification\n",
    "                    for new_state, new_group in first_classification_result.items():\n",
    "                        if len(new_group) > 6:\n",
    "                            # If the new group still has more than 6 species, recursively call classify_first_group to continue subdividing\n",
    "                            groups.append((new_state, new_group))\n",
    "                        else:\n",
    "                            # If the new group has 6 or fewer species, directly classify it\n",
    "                            groups.append((new_state, new_group))\n",
    "                else:\n",
    "                    # Use classify_group to classify datasets with 6 or fewer species\n",
    "                    classification_result = classify_group(current_group)\n",
    "                    classification_results[state] = classification_result  # Store API call result\n",
    "                    \n",
    "                    # Add the new group results to groups for further classification\n",
    "                    for new_state, new_group in classification_result.items():\n",
    "                        groups.append((new_state, new_group))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing group with state: {state}, species: {current_group}\")  # Error debug information\n",
    "            print(f\"Exception: {e}\")\n",
    "            raise e\n",
    "    return final_classification\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3793898d3a2ffb7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "need to set up an empty dataset, to store these results at the same time need to call a piece of it, which if you are considering the storage of the results of these two final storage lists: final_classification, classification_results; the first of these storage lists final is used for a case, that is, the initial character directly separate out a species, but this problem may also need to consider the place is needed again when the number of species is greater than 6 may also need to use this place"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26c62491614d6050"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial groups: [['Ancylolomia', 'Calamotropha', 'Catoptria', 'Chrysocrambus', 'Chrysoteuchia', 'Crambus', 'Donacaula', 'Pediasia', 'Platytes', 'Schoenobius', 'Thisanotia']]\n",
      "Initial final_classification: {}\n",
      "Initial classification_results: {}\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'state' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 4\u001B[0m, in \u001B[0;36mrecursive_classification\u001B[1;34m(groups, final_classification, classification_results)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m----> 4\u001B[0m     state, current_group \u001B[38;5;241m=\u001B[39m groups\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;241m0\u001B[39m)  \u001B[38;5;66;03m# Extract the first tuple from groups, containing state identifier and current group of species\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing group with state: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, species: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_group\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# Print the current group's state and species for debugging\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitial classification_results:\u001B[39m\u001B[38;5;124m\"\u001B[39m, classification_results)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Call the recursive_classification function to process the groups and store the results\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m final_classification \u001B[38;5;241m=\u001B[39m \u001B[43mrecursive_classification\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_classification\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclassification_results\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Print the final classification results\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal Classification:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[6], line 14\u001B[0m, in \u001B[0;36mrecursive_classification\u001B[1;34m(groups, final_classification, classification_results)\u001B[0m\n\u001B[0;32m     11\u001B[0m         classification_results[state] \u001B[38;5;241m=\u001B[39m classification_result  \u001B[38;5;66;03m# Store the API classification result in classification_results dictionary using state as the key\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# Catch and handle any exceptions that may occur\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError processing group with state: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mstate\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, species: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_group\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# Print the error message and current group's state and species for debugging\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mException: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# Print the details of the exception\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e  \u001B[38;5;66;03m# Re-raise the exception so that it can be handled by the caller\u001B[39;00m\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m: cannot access local variable 'state' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# Assume the variables have been initialized\n",
    "# Dictionary to store the final classification where each species is classified individually\n",
    "final_classification = {}\n",
    "\n",
    "# Dictionary to store the API classification results for each state\n",
    "classification_results = {}\n",
    "\n",
    "# Print the initial state of groups and dictionaries for debugging purposes\n",
    "print(\"Initial groups:\", groups)\n",
    "print(\"Initial final_classification:\", final_classification)\n",
    "print(\"Initial classification_results:\", classification_results)\n",
    "\n",
    "# Call the recursive_classification function to process the groups and store the results\n",
    "final_classification = recursive_classification(groups, final_classification, classification_results)\n",
    "\n",
    "# Print the final classification results\n",
    "print(\"Final Classification:\")\n",
    "print(json.dumps(final_classification, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Print the classification results from the API calls\n",
    "print(\"\\nClassification Results:\")\n",
    "print(json.dumps(classification_results, indent=2, ensure_ascii=False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T02:17:41.849139Z",
     "start_time": "2024-06-07T02:17:41.826597Z"
    }
   },
   "id": "3dd08ef6da738455",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "When the final result is stored in the final_classification, we need to consider the use of this result needs to be parsed and integrated, stored in the final result of the dictionary form. Then we first need to consider the results of the different API calls to extract the key content, and then analyze them separately, and then and the results of the good conversion into a whole, and parsing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6bda07fcf29d43d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Through the results obtained from the previous distributed traversal loop, i.e., the classification results of all different feature states in the initial character, the classification results of the API calls again\n",
    "# print(result1)\n",
    "# print(result2)\n",
    "# print(result3)\n",
    "\n",
    "# We need to extract the most critical parts from these three sections, namely the classification paths of species in each subgroup.\n",
    "# In each distributed loop result, we need to specify that the final results should store the classification results of species in each subgroup in the block (Final Taxonomic Key). \n",
    "# Then, by constructing an extraction function, we can extract the final classification information.\n",
    "\n",
    "# Define a function to extract the required part from each result\n",
    "def extract_final_taxonomic_key(result):\n",
    "    match = re.search(r'Final Taxonomic Key(.*)', result, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Extract the required part from each result\n",
    "final_taxonomic_key1 = extract_final_taxonomic_key(final_classification[0])\n",
    "final_taxonomic_key2 = extract_final_taxonomic_key(final_classification[1])\n",
    "final_taxonomic_key3 = extract_final_taxonomic_key(final_classification[2])\n",
    "\n",
    "# Print the extracted results\n",
    "print(\"Final Taxonomic Key 1:\\n\", final_taxonomic_key1)\n",
    "print(\"Final Taxonomic Key 2:\\n\", final_taxonomic_key2)\n",
    "print(\"Final Taxonomic Key 3:\\n\", final_taxonomic_key3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c05ac4ab54eeace0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "A simple example of how the results of parsing may end up being stored:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "856381b06282ebed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result1_1 = \"\"\"\n",
    "1. Character18\n",
    "   - 1 and 2: Equisetum_palustre\n",
    "   - 1: Equisetum_litorale\n",
    "\"\"\"\n",
    "result2_1 = \"\"\"\n",
    "1. Character8\n",
    "   - 1: \n",
    "     - Character7\n",
    "       - 1: Equisetum_ramosissimum\n",
    "       - 2 and 3: \n",
    "         - Character26\n",
    "           - 1: Equisetum_variegatum\n",
    "           - 2: Equisetum_trachyodon\n",
    "       - 3: Equisetum_hyemale\n",
    "   - 2: \n",
    "     - Character9\n",
    "       - 1: Equisetum_moorei\n",
    "       - 2: Equisetum_pratense\n",
    "\"\"\"\n",
    "result3_1 =\"\"\"\n",
    "1. Character2\n",
    "   - 1: \n",
    "     - Character10\n",
    "       - 1: Equisetum_telmateia\n",
    "       - 2: Equisetum_arvense\n",
    "   - 2: \n",
    "     - Character20\n",
    "       - 2 and 3: Equisetum_pratense\n",
    "       - 3: Equisetum_sylvaticum\n",
    "   - 3: Equisetum_fluviatile\n",
    "\"\"\"\n",
    "\n",
    "# Define a function to parse each result string\n",
    "def parse_result(result):\n",
    "    lines = result.strip().split('\\n')\n",
    "    result_dict = {}\n",
    "    stack = [(0, result_dict)]  # Use tuples to record indentation level and current dictionary\n",
    "    for line in lines:\n",
    "        indent_level = len(line) - len(line.lstrip())\n",
    "        current_dict = stack[-1][1]\n",
    "        # Adjust stack to match current indentation level\n",
    "        while stack and stack[-1][0] >= indent_level:\n",
    "            stack.pop()\n",
    "        \n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            \n",
    "            if value:\n",
    "                current_dict[key] = value\n",
    "            else:\n",
    "                current_dict[key] = {}\n",
    "                stack.append((indent_level, current_dict[key]))\n",
    "        else:\n",
    "            key = line.strip()\n",
    "            current_dict[key] = {}\n",
    "            stack.append((indent_level, current_dict[key]))\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# Parse each result string\n",
    "parsed_result1 = parse_result(result1_1)\n",
    "parsed_result2 = parse_result(result2_1)\n",
    "parsed_result3 = parse_result(result3_1)\n",
    "\n",
    "# Check if the parsing results are correct\n",
    "parsed_results = [parsed_result1, parsed_result2, parsed_result3]\n",
    "\n",
    "# Check the number of keys in the initial classification results\n",
    "initial_keys = list(initial_classification.keys())\n",
    "\n",
    "# Check if the numbers match\n",
    "if len(parsed_results) != len(initial_keys):\n",
    "    print(\"Error: Parsed results and initial keys do not match in length.\")\n",
    "else:\n",
    "    # Build the main dictionary\n",
    "    nested_structure = {}\n",
    "    for key, parsed_result in zip(initial_keys, parsed_results):\n",
    "        nested_structure[key] = parsed_result\n",
    "    \n",
    "    # Print the nested structure\n",
    "    import json\n",
    "    print(json.dumps(nested_structure, indent=2))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da502e3587e6bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
