{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import json  # For handling JSON data\n",
    "from openai import OpenAI  # For interacting with OpenAI API\n",
    "import os  # For interacting with the operating system, such as file paths\n",
    "import re  # For regular expressions, useful for pattern matching in strings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file with encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "# Function to convert letter to number\n",
    "def letter_to_number(letter):\n",
    "    return str(ord(letter) - ord('A') + 10)\n",
    "\n",
    "# Function to parse matrix content\n",
    "def parse_matrix(matrix_content):\n",
    "    data = []\n",
    "    headers = []\n",
    "    lines = matrix_content.strip().split('\\n')\n",
    "    for i in range(0, len(lines), 2):\n",
    "        taxa = lines[i].strip().strip(\"'\")\n",
    "        traits = lines[i + 1].strip()\n",
    "        species_traits = []\n",
    "        j = 0\n",
    "        while j < len(traits):\n",
    "            if traits[j] == '(':\n",
    "                j += 1\n",
    "                states = ''\n",
    "                while traits[j] != ')':\n",
    "                    if traits[j].isalpha():\n",
    "                        states += letter_to_number(traits[j])\n",
    "                    else:\n",
    "                        states += traits[j]\n",
    "                    j += 1\n",
    "                species_traits.append(','.join(states))\n",
    "            elif traits[j] == '?':\n",
    "                species_traits.append('Missing')\n",
    "            elif traits[j] == '-':\n",
    "                species_traits.append('Not Applicable')\n",
    "            elif traits[j].isalpha():\n",
    "                species_traits.append(letter_to_number(traits[j]))\n",
    "            else:\n",
    "                species_traits.append(traits[j])\n",
    "            j += 1\n",
    "        data.append([taxa] + species_traits)\n",
    "    max_traits = max(len(row) - 1 for row in data)\n",
    "    headers = ['taxa'] + [f'Character{i + 1}' for i in range(max_traits)]\n",
    "    try:\n",
    "        df = pd.DataFrame(data, columns=headers)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to convert NEXUS to CSV\n",
    "def convert_nexus_to_csv(file_path, output_path):\n",
    "    try:\n",
    "        encodings = ['utf-8', 'gbk', 'latin1']  # List of encodings to try\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding=encoding) as file:\n",
    "                    content = file.read()\n",
    "                print(f\"Successfully read file with encoding: {encoding}\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Failed to read file with encoding: {encoding}\")\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError(\"Failed to read file with all attempted encodings.\")\n",
    "        \n",
    "        matrix_content = re.search(r'MATRIX\\s*(.*?)\\s*;', content, re.DOTALL).group(1).strip()\n",
    "        df = parse_matrix(matrix_content)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Appear error：{e}\")\n",
    "\n",
    "# Function to build knowledge graph from CSV\n",
    "def build_knowledge_graph(matrix):\n",
    "    knowledge_graph = {}\n",
    "    for _, row in matrix.iterrows():\n",
    "        taxa = row.iloc[0]\n",
    "        characteristics = {}\n",
    "        for col in matrix.columns[1:]:\n",
    "            state = row[col]\n",
    "            if isinstance(state, str) and ',' in state:\n",
    "                state = state.replace(',', ' and ')\n",
    "            characteristics[col] = str(state)\n",
    "        knowledge_graph[taxa] = {'Characteristics': characteristics}\n",
    "    return knowledge_graph\n",
    "\n",
    "# Function to save knowledge graph as JSON\n",
    "def save_knowledge_graph_as_json(knowledge_graph, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(knowledge_graph, f, indent=4)\n",
    "\n",
    "# Main function to combine all steps\n",
    "def nexus_to_knowledge_graph(nexus_file_path, csv_output_path, json_output_path):\n",
    "    # Step 1: Convert NEXUS to CSV\n",
    "    df = convert_nexus_to_csv(nexus_file_path, csv_output_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Step 2: Build the knowledge graph from the DataFrame\n",
    "        knowledge_graph = build_knowledge_graph(df)\n",
    "        \n",
    "        # Step 3: Save the knowledge graph as a JSON file\n",
    "        save_knowledge_graph_as_json(knowledge_graph, json_output_path)\n",
    "        \n",
    "        # Optional: Print the JSON structure for verification\n",
    "        knowledge_graph_json = json.dumps(knowledge_graph, indent=4)\n",
    "        # print(knowledge_graph_json)\n",
    "        \n",
    "        # Return the knowledge graph for further use\n",
    "        return knowledge_graph\n",
    "    else:\n",
    "        print(\"Failed to create the DataFrame from NEXUS file.\")\n",
    "        return None\n",
    "\n",
    "# Example Usage\n",
    "nexus_file_path = \"D:/桌面/taxonomy_primary_result/The_GPT-4_result/Dataset_3 (The Lycopodiales (Diphasiastrum, Huperzia, Isoetes, Lycopodium, Selaginella)) 4/Information gain methods/nexdata\"\n",
    "csv_output_path = \"D:/桌面/process_data_2.csv\"\n",
    "json_output_path = \"D:/桌面/knowledge_graph.json\"\n",
    "# Process the file and get the knowledge graph\n",
    "knowledge_graph = nexus_to_knowledge_graph(nexus_file_path, csv_output_path, json_output_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:30:56.858265Z",
     "start_time": "2024-06-14T01:30:56.845905Z"
    }
   },
   "id": "91e8e0ed78d47d3b",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'description': 'stems <elongation>', 'states': {'1': 'elongated, with numerous small', '2': 'short and tuberous, with sheat'}}, '2': {'description': 'stems <carriage>', 'states': {'1': 'suberect, and rooting at the b', '2': 'creeping, and rooting directly', '3': 'creeping, and rooting from cha'}}, '3': {'description': 'stems <manner of branching>', 'states': {'1': 'overtly dichotomising vegetati', '2': 'ostensibly monopodial vegetati'}}, '4': {'description': 'stems <whether dorsiventral>', 'states': {'1': 'dorsiventrally organized, with', '2': 'not dorsiventrally organized'}}, '5': {'description': 'stems <whether with flattened', 'states': {'1': 'with non-flattened branches', '2': 'with only slightly flattened b', '3': 'with strongly flattened branch'}}, '6': {'description': 'stems <presence of secondary t', 'states': {'1': 'with anomalous secondary thick', '2': 'without secondary thickening'}}, '7': {'description': 'the old leaf bases <in Isoetes', 'states': {'1': 'persistent on the stem, short', '2': 'not persistent'}}, '8': {'description': 'leaves <whether ligulate>', 'states': {'1': 'ligulate', '2': 'eligulate'}}, '9': {'description': 'leaves <arrangement>', 'states': {'1': '4-ranked on the branches', '2': 'not 4-ranked'}}, '10': {'description': '<foliage> leaves <heterophylly', 'states': {'1': 'of two kinds: those of the two', '2': 'all alike and spirally arrange'}}, '11': {'description': '<foliage> leaves <appressed or', 'states': {'1': 'appressed', '2': 'spreading'}}, '12': {'description': 'leaves <whether hair-pointed>', 'states': {'1': 'with long, filiform hair-like', '2': 'not hair-pointed'}}, '13': {'description': '<heterosporous or homosporous>', 'states': {'1': 'homosporous', '2': 'heterosporous'}}, '14': {'description': 'sporophylls <modified or leafl', 'states': {'1': 'resembling the foliage leaves', '2': 'differing markedly from the fo'}}, '15': {'description': 'sporophylls <arrangement>', 'states': {'1': 'aggregated into well defined t', '2': 'in fertile zones tending to al'}}, '16': {'description': 'cones <carriage>', 'states': {'1': 'sessile at the tips of the nor', '2': 'on long, erect peduncles which'}}, '17': {'description': 'the sporangia', 'states': {'1': 'basal and subsessile on the ad', '2': 'very large, transversely and l'}}, '18': {'description': 'the megaspores <of Isoetes, su', 'states': {'1': 'covered with short, blunt tube', '2': 'covered with long, fragile spi', '3': 'with a reticulate ornamentatio'}}, '19': {'description': '<terrestrial or aquatic:>', 'states': {'1': 'terrestrial', '2': 'aquatic'}}, '20': {'description': '<habitat elevation:>', 'states': {'1': 'lowland', '2': 'upland', '3': 'montane'}}, '21': {'description': '<habitat when terrestrial:>', 'states': {'1': 'bogs', '2': 'heaths', '3': 'sandy places', '4': 'rock ledges'}}, '22': {'description': 'family', 'states': {'1': 'Lycopodiaceae', '2': 'Selaginellacae', '3': 'Isoetaceae'}}}\n"
     ]
    }
   ],
   "source": [
    "def parse_charlabels(charlabels_content):\n",
    "    charlabels = {}\n",
    "    lines = charlabels_content.strip().split(\"\\n\")\n",
    "    char_pattern = re.compile(r\"\\[(\\d+)\\(\\d+\\)\\]\\s+'(.+?)'\")\n",
    "    for line in lines:\n",
    "        match = char_pattern.match(line.strip().rstrip(','))\n",
    "        if match:\n",
    "            char_index = int(match.group(1))\n",
    "            description = match.group(2)\n",
    "            charlabels[char_index] = description\n",
    "    return charlabels\n",
    "\n",
    "def parse_statelabels(statelabels_content):\n",
    "    statelabels = {}\n",
    "    lines = statelabels_content.strip().split(\"\\n\")\n",
    "    current_char = None\n",
    "    states = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r'^\\d+', line):\n",
    "            if current_char is not None:\n",
    "                statelabels[current_char] = states\n",
    "            parts = line.split(' ', 1)\n",
    "            current_char = int(parts[0])\n",
    "            states = parts[1].strip().strip(',').split(\"' '\")\n",
    "            states = [state.strip(\"'\") for state in states]\n",
    "        else:\n",
    "            additional_states = line.strip().strip(',').split(\"' '\")\n",
    "            additional_states = [state.strip(\"'\") for state in additional_states]\n",
    "            states.extend(additional_states)\n",
    "\n",
    "    if current_char is not None:\n",
    "        statelabels[current_char] = states\n",
    "\n",
    "    return statelabels\n",
    "\n",
    "def combine_labels_and_states(charlabels, statelabels):\n",
    "    character_info = {}\n",
    "    for char_index, description in charlabels.items():\n",
    "        states = statelabels.get(char_index, [])\n",
    "        state_dict = {str(i + 1): state for i, state in enumerate(states)}\n",
    "        character_info[str(char_index)] = {\n",
    "            \"description\": description,\n",
    "            \"states\": state_dict\n",
    "        }\n",
    "    return character_info\n",
    "\n",
    "def extract_nexus_sections(nexus_content):\n",
    "    charlabels_content = \"\"\n",
    "    statelabels_content = \"\"\n",
    "    lines = nexus_content.strip().split(\"\\n\")\n",
    "    in_charlabels = False\n",
    "    in_statelabels = False\n",
    "\n",
    "    for line in lines:\n",
    "        if \"CHARLABELS\" in line:\n",
    "            in_charlabels = True\n",
    "            continue\n",
    "        if \"STATELABELS\" in line:\n",
    "            in_statelabels = True\n",
    "            continue\n",
    "        if \";\" in line:\n",
    "            in_charlabels = False\n",
    "            in_statelabels = False\n",
    "        \n",
    "        if in_charlabels:\n",
    "            charlabels_content += line + \"\\n\"\n",
    "        if in_statelabels:\n",
    "            statelabels_content += line + \"\\n\"\n",
    "\n",
    "    return charlabels_content, statelabels_content\n",
    "\n",
    "def parse_nexus_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        nexus_content = file.read()\n",
    "\n",
    "    charlabels_content, statelabels_content = extract_nexus_sections(nexus_content)\n",
    "    \n",
    "    # Analyzing the CHARLABELS section\n",
    "    charlabels = parse_charlabels(charlabels_content)\n",
    "\n",
    "    # Analyzing the STATELABELS section\n",
    "    statelabels = parse_statelabels(statelabels_content)\n",
    "\n",
    "    # Combine parsing results to generate character_info dictionary\n",
    "    character_info = combine_labels_and_states(charlabels, statelabels)\n",
    "    \n",
    "    return character_info\n",
    "\n",
    "# 示例使用\n",
    "file_path = \"D:/桌面/taxonomy_primary_result/The_GPT-4_result/Dataset_3 (The Lycopodiales (Diphasiastrum, Huperzia, Isoetes, Lycopodium, Selaginella)) 4/Information gain methods/nexdata\"\n",
    "character_info = parse_nexus_file(file_path)\n",
    "print(character_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T03:48:47.578012Z",
     "start_time": "2024-06-14T03:48:47.570785Z"
    }
   },
   "id": "66717161ee5ba02b",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initial Character Classify Result #\n",
      "```\n",
      "{\n",
      "    \"Character\": \"Character1\",\n",
      "    \"States\": {\n",
      "        \"1\": [\"Diphasiastrum alpinum\", \"Diphasiastrum complanatum\", \"Huperzia selago\", \"Lycopodiella inundata\", \"Lycopodium annotinum\", \"Lycopodium clavatum\", \"Selaginella kraussiana\", \"Selaginella selaginoides\"],\n",
      "        \"2\": [\"Isoetes echinospora\", \"Isoetes histrix\", \"Isoetes lacustris\"]\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Input the API key and morphological matrix\n",
    "# Initialize the OpenAI client with the API key from environment variables\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "# This code sets up the prompt for the API input using the client.chat.completions.create interface\n",
    "# to conduct multi-turn conversations. By assigning different roles in the conversation (user, assistant, system),\n",
    "# all input information is fully conveyed to the API model.\n",
    "messages_initial = [\n",
    "    # Set the system role to focus on taxonomy tasks.\n",
    "    # Emphasize the system's understanding of morphological matrices, information gain,\n",
    "    # and the construction of classification keys in the system setup.\n",
    "    {\"role\": \"system\",\n",
    "     \"content\":\n",
    "         \"\"\"You are a helpful taxonomist assistant.\n",
    "         You are skilled at calculating the correct information gain to choose the character that best divides species into even groups based on their states.\n",
    "         Based on the selected character, classify the species into different groups according to their states.\n",
    "         For each group with more than two species, continue selecting characters to further classify this group until each group only has one species.\n",
    "         After multiple classifications, determine the final classification levels and record each classifying character and its state. \n",
    "         Finally, generate a taxonomic key.\n",
    "         You need to strictly ensure that you categorize all species when selecting the initial character, and that you don't ignore any of the species.\n",
    "         Please format the classification result as follows:\n",
    "        ```\n",
    "        {\n",
    "            \"Character\": \"Character1\",\n",
    "            \"States\": {\n",
    "                \"State 1\": [\"species1\", \"species2\", ...],\n",
    "                \"State 2\": [\"species3\", \"species4\", ...],\n",
    "                \"State ...\": [\"species5\", \"species6\", ...]\n",
    "            }\n",
    "        }\n",
    "        ```\n",
    "        Ensure that the response follows this format exactly.\n",
    "        Additionally,exactly ensure that all species are included in the initial classification result.\n",
    "         \"\"\"},\n",
    "\n",
    "    # Input the main task request, construct the classification key, and emphasize the details needed for classification.\n",
    "    # This includes: the main objective, information gain calculation, ignoring invalid states, clarifying multi-character states,\n",
    "    # guiding correct selection based on the significance of information gain, and standardizing the final output format for subsequent extraction of API results.\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"\"\"\n",
    "                Generate the taxonomic key based on the provided morphological matrix. The matrix includes all species and their different states for each character.\n",
    "                The process involves selecting a character to classify the species into groups. Repeat this classification within each subgroup until each group contains only one species.\n",
    "                Information gain measures how much the uncertainty in the dataset is reduced after using a character for classification. It helps in selecting characters that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "                Please select the initial classification character for all species based on the morphological matrix and information gain methods.\n",
    "                In the morphological matrix, 'Missing' and 'Not applicable' are invalid states. If a character has invalid states for the group being classified, it should be ignored.\n",
    "                States are represented by numbers, and like the '1 and 2' means multiple states should be treated as a single state type.(such as '3' and '2 and 3'  is the different state, these are two separate states, when i choose character to based on different state to distinguish the species)\n",
    "                You need to calculate the information gain for each character, and choose the highest information gain result, The higher the Information Gain result, the greater the contribution of the feature to the classification.\n",
    "                Now I will show you the morphological matrix. Please provide only the initial classification character and the categorization of species based on its state, and you should singly show this called as # initial character classify result #\n",
    "            \"\"\"},\n",
    "\n",
    "    # Use the assistant to summarize and refine the prompt content for the API.\n",
    "    # Through the conversation with the assistant, deepen the API understanding of the content to some extent,\n",
    "    # control the API response results, and standardize the output format of the API response.\n",
    "    {\"role\": \"assistant\",\n",
    "     \"content\": \"\"\"\n",
    "                Understood. I will generate the taxonomic key based on the provided morphological matrix. Here is a summary of the steps I will follow:\n",
    "                1. The matrix includes all species and their different states for each character.\n",
    "                2. I will select a character to classify the species into groups and repeat this classification within each subgroup until each group contains only one species, and i'll not ignore any species.\n",
    "                3. I will use information gain to measure how much the uncertainty in the dataset is reduced after using a feature for classification. This helps in selecting features that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "                4. I will select the initial classification character for all species based on the morphological matrix and information gain methods.\n",
    "                5. In the morphological matrix, 'Missing' and 'Not applicable' are considered invalid states. If a character has invalid states for the group being classified, it will be ignored.\n",
    "                6. States are represented by numbers. For example, '1 and 2' means multiple states should be treated as a single state type. (such as '1' and '1 and 2'  is the different state, these are two separate states, when i choose character to based on different state to distinguish the species)\n",
    "                7. I will use information gain to calculate all character and choose the highest information gain result, The higher the Information Gain result, the greater the contribution of the feature to the classification.so i need to make sure the result is Average classification\n",
    "                8. The final result will provide only the initial classification character and the categorization of species based on its state.\n",
    "                9. I will use all the species in their entirety, strictly making sure to categorize all of them! (need to make sure contain all species)\n",
    "                10. Don't need to show how i calculate, only need to show the final result, and please show the final result in #initail character classify result# block, Don't have errors where the state and species don't match\n",
    "                Please provide the morphological matrix data so that I can proceed with the initial classification.\n",
    "            \"\"\"},\n",
    "\n",
    "    # Input the corresponding morphological matrix information for analysis.\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": f\"Here is morphological matrix:{knowledge_graph}\"}\n",
    "]\n",
    "\n",
    "# Set various parameters to control the API response. \n",
    "# Setting the temperature to 0 and limiting max_tokens to save costs and avoid long, redundant outputs.\n",
    "initial_character_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages_initial ,\n",
    "    stop=None,\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    n=1\n",
    ")\n",
    "\n",
    "# Store the API call response results as a file. \n",
    "# (For subsequent distributed API call loops, consider storing in environment variables for continuous calls and modifications).\n",
    "initial_response = initial_character_info.choices[0].message.content\n",
    "\n",
    "# If used as a whole pipeline to transfer the results, ignore this print. \n",
    "# However, for debugging, you can use this print statement to check the response.\n",
    "print(initial_response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:31:09.779345Z",
     "start_time": "2024-06-14T01:31:06.236111Z"
    }
   },
   "id": "745a246dd5ad4af",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{'Character': 'Character1', 'States': {'1': ['Diphasiastrum alpinum', 'Diphasiastrum complanatum', 'Huperzia selago', 'Lycopodiella inundata', 'Lycopodium annotinum', 'Lycopodium clavatum', 'Selaginella kraussiana', 'Selaginella selaginoides'], '2': ['Isoetes echinospora', 'Isoetes histrix', 'Isoetes lacustris']}}\n",
      "[('1', ['Diphasiastrum alpinum', 'Diphasiastrum complanatum', 'Huperzia selago', 'Lycopodiella inundata', 'Lycopodium annotinum', 'Lycopodium clavatum', 'Selaginella kraussiana', 'Selaginella selaginoides']), ('2', ['Isoetes echinospora', 'Isoetes histrix', 'Isoetes lacustris'])]\n",
      "('1', ['Diphasiastrum alpinum', 'Diphasiastrum complanatum', 'Huperzia selago', 'Lycopodiella inundata', 'Lycopodium annotinum', 'Lycopodium clavatum', 'Selaginella kraussiana', 'Selaginella selaginoides'])\n",
      "('2', ['Isoetes echinospora', 'Isoetes histrix', 'Isoetes lacustris'])\n"
     ]
    }
   ],
   "source": [
    "def parse_classification_result(result_text):\n",
    "    classification = {\"Character\": None, \"States\": {}}\n",
    "    try:\n",
    "        # Attempt to match the Character\n",
    "        character_match = re.search(r'\"Character\": \"([^\"]+)\"', result_text)\n",
    "        if character_match:\n",
    "            classification[\"Character\"] = character_match.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Character not found in the result text.\")\n",
    "\n",
    "        # Attempt to match each State and the corresponding species\n",
    "        state_sections = re.findall(r'\"(\\d+|[^\"]+)\":\\s*\\[(.*?)\\]', result_text)\n",
    "        if not state_sections:\n",
    "            raise ValueError(\"No states found in the result text.\")\n",
    "\n",
    "        for state, species_block in state_sections:\n",
    "            species_list = re.findall(r'\"([^\"]+)\"', species_block)\n",
    "            if not species_list:\n",
    "                raise ValueError(f\"No species found for state {state}.\")\n",
    "            classification[\"States\"][state] = species_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing classification result: {e}\")\n",
    "        # Decide whether to return an empty classification or raise an exception when an error occurs\n",
    "        raise e  # Or return classification\n",
    "\n",
    "    return classification\n",
    "print(type(initial_response))\n",
    "parsed_initial_classification = parse_classification_result(initial_response)\n",
    "print(parsed_initial_classification)\n",
    "\n",
    "# Function to generate groups from the classification result\n",
    "def generate_groups_from_classification(classification_result):\n",
    "    \"\"\"\n",
    "    Generate groups from classification result.\n",
    "    \n",
    "    :param classification_result: Dictionary containing the classification result\n",
    "    :return: List of tuples, where each tuple contains a state and a list of species\n",
    "    \"\"\"\n",
    "    groups = []\n",
    "    for state, species_list in classification_result[\"States\"].items():\n",
    "        groups.append((state, species_list))\n",
    "    return groups\n",
    "\n",
    "# Generate groups from the parsed initial classification\n",
    "groups = generate_groups_from_classification(parsed_initial_classification)\n",
    "print(groups)\n",
    "print(groups[0])\n",
    "print(groups[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T03:48:11.258480Z",
     "start_time": "2024-06-14T03:48:11.251613Z"
    }
   },
   "id": "86ea88ee692db823",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# API call function for continued grouping for each subgroup\n",
    "def classify_group(group_species):\n",
    "    # Create a sub-matrix for the group of species\n",
    "    group_matrix = {species: knowledge_graph[species] for species in group_species}\n",
    "    group_matrix_str = json.dumps(group_matrix, ensure_ascii=False)\n",
    "    \n",
    "    # Define the messages for the API call\n",
    "    messages_secondary = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             You are a helpful taxonomist assistant.\n",
    "             You are skilled at calculating the correct information gain to choose the character that best divides species into even groups based on their states.\n",
    "             Based on the selected character, classify the species into different groups according to their states.\n",
    "             For each group with more than two species, continue selecting characters to further classify this group until each group only has one species.\n",
    "             After multiple classifications, determine the final classification levels and record each classifying character and its state.\n",
    "             Finally, generate a taxonomic key.\n",
    "             ***IMPORTANT: Ensure that each group contains only one species in the final classification result. don't appear the result like state :[species A, species B], need to choose character continue class this teo species***\n",
    "             \"\"\"},\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Generate the nested taxonomic key based on the provided morphological matrix.\n",
    "             The process involves selecting a character to classify the species into groups. Repeat this classification within each subgroup until each group contains only one species.\n",
    "             Information gain measures how much the uncertainty in the dataset is reduced after using a character for classification. It helps in selecting characters that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "             Please select the classification character for these group's species based on the morphological matrix and information gain methods.\n",
    "             In the morphological matrix, 'Missing' and 'Not applicable' are invalid states. If a character has invalid states for the group being classified, it should be ignored.\n",
    "             States are represented by numbers. For example, '1 and 2' means multiple states should be treated as a single state type and this multi-state characterization should not be confused with the single states within it (the state of '3' and '2 and 3' is different state, when you choose the character to based on the state to distinguish need to careful handle). The initial character should have no more than three state types.\n",
    "             You need to calculate the information gain for each character and choose the highest information gain result. The higher the information gain result, the greater the contribution of the feature to the classification.\n",
    "             After selecting the initial classification character and categorizing the species based on its state, repeat the process within each subgroup. For each subgroup, select the character with the highest information gain to further classify the species. Continue this process recursively until each group contains only one species.\n",
    "             Now I will show you the morphological matrix. Please provide the classification character and the categorization of species based on its state. Then, continue to classify each subgroup recursively, showing the chosen character and categorization for each subgroup. Please present the result in a structured format, with each step clearly labeled.\n",
    "             Please don't show how you analyze and calculate, please show me the final result.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Understood. I will generate the nested taxonomic key based on the provided morphological matrix. Here is a summary of the steps I will follow:\n",
    "             1. The matrix includes all species and their different states for each character.\n",
    "             2. I will select a character to classify the species into groups and repeat this classification within each subgroup until each group contains only one species.\n",
    "             3. I will use information gain to measure how much the uncertainty in the dataset is reduced after using a feature for classification. This helps in selecting features that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "             4. I will select the classification character for the group's species based on the morphological matrix and information gain methods.\n",
    "             5. In the morphological matrix, 'Missing' and 'Not applicable' are considered invalid states. If a character has invalid states for the group being classified, it will be ignored.\n",
    "             6. States are represented by numbers. For example, '2 and 3' means multiple states should be treated as a single state type, and this multi-state characterization should not be confused with the individual states (like '2', '3') within it (such as '3' and '2 and 3' are different states, these are two separate states, when I choose a character based on different states to distinguish the species). The classification character should have no more than three state types.\n",
    "             7. I will use information gain to calculate all characters and choose the highest information gain result. The higher the information gain result, the greater the contribution of the feature to the classification.\n",
    "             8. The final result will provide only the initial classification character and the categorization of species based on its state.\n",
    "             9. Don't need to show how the process about choosing, only need to show the final result as a nested structure, and I will store the result in #character classify result# block.\n",
    "             Please provide the group morphological matrix data so that I can proceed with the classification.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the group information need to be classify and include the morphological matrix {group_matrix_str}\"}\n",
    "    ]\n",
    "    \n",
    "    # Make the API call to classify the group\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages_secondary,\n",
    "        stop=None,\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "        n=1\n",
    "    )\n",
    "    result_secondary = response.choices[0].message.content\n",
    "    # print(f\"API response for group {group_species}: {result}\")\n",
    "    \n",
    "    # Define messages for formatting the response to JSON\n",
    "    messages_JSON = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             You are a helpful JSON format converter.\n",
    "             You can express the nested structure as a JSON result based on the corresponding content.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Please format the classification result as follows:\n",
    "             ```\n",
    "             # Final taxonomic key result JSON format #\n",
    "             {\n",
    "                 \"Character\": \"CharacterX\",\n",
    "                 \"States\": {\n",
    "                     \"1\": [\"speciesA\"],\n",
    "                     \"2\": {\n",
    "                         \"Character\": \"CharacterY\",\n",
    "                         \"States\": {\n",
    "                             \"1\": [\"speciesB\"],\n",
    "                             \"2\": [\"speciesC\"]\n",
    "                         }\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "             ```\n",
    "             Ensure that the response follows this format exactly.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Understood. I'll convert the nested structure you gave me into JSON format and store it in # final result #.\n",
    "             Please provide what you need to convert the format.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here are the taxonomic results for the nested schema representation {result_secondary}\"}\n",
    "    ]\n",
    "    \n",
    "    # Make the API call to format the response as JSON\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages_JSON,\n",
    "        stop=None,\n",
    "        temperature=0,\n",
    "        max_tokens=1500,\n",
    "        n=1\n",
    "    )\n",
    "    json_result = response.choices[0].message.content\n",
    "    print(json_result)\n",
    "    return json_result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:31:14.227906Z",
     "start_time": "2024-06-14T01:31:14.221723Z"
    }
   },
   "id": "c0a264c44051420",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to clean and extract JSON string\n",
    "def extract_json_string(json_string):\n",
    "    # Find the positions of the start and end of the JSON object\n",
    "    start = json_string.find('{')\n",
    "    end = json_string.rfind('}') + 1\n",
    "    \n",
    "    # If both start and end positions are valid, extract and return the JSON string\n",
    "    if start != -1 and end != -1:\n",
    "        cleaned_string = json_string[start:end]\n",
    "        return cleaned_string.strip()\n",
    "    \n",
    "    # If positions are not valid, return an empty string\n",
    "    return \"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:31:17.722768Z",
     "start_time": "2024-06-14T01:31:17.719420Z"
    }
   },
   "id": "6bcc77085713e069",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def recursive_classification(groups, final_classification, classification_results, depth=0, max_depth=10):\n",
    "    \"\"\"\n",
    "    Recursive classification function to process groups and store results.\n",
    "    :param groups: Groups to be processed\n",
    "    :param final_classification: Final classification result\n",
    "    :param classification_results: Classification results\n",
    "    :param depth: Current recursion depth\n",
    "    :param max_depth: Maximum recursion depth\n",
    "    :return: Final classification result\n",
    "    \"\"\"\n",
    "    # Continue looping while the groups list is not empty\n",
    "    # Initialize state and current_group for error handling\n",
    "    state, current_group = None, []\n",
    "    while groups:\n",
    "        try:\n",
    "            # Pop the first group from the list, getting the state and current group of species\n",
    "            state, current_group = groups.pop(0)\n",
    "            print(f\"Processing group with state: {state}, species: {current_group}, at depth: {depth}\")\n",
    "\n",
    "            # If the current group has only one species, add it to the final classification\n",
    "            if len(current_group) == 1:\n",
    "                final_classification[current_group[0]] = current_group\n",
    "            # If the current recursion depth has reached the maximum depth, stop further classification\n",
    "            elif depth >= max_depth:\n",
    "                print(f\"Reached max depth {max_depth}. Stopping further classification for group: {current_group}\")\n",
    "                final_classification[state] = current_group\n",
    "            else:\n",
    "                # Call the classify_group function to classify the current group\n",
    "                classification_result = classify_group(current_group)\n",
    "                # Clean the API classification result to extract the JSON string\n",
    "                cleaned_classification_result = extract_json_string(classification_result)  \n",
    "                # Store the classification result in classification_results\n",
    "                classification_results[state] = cleaned_classification_result\n",
    "\n",
    "                # Parse the classification result, create new subgroups, and add them to groups for further classification\n",
    "                parsed_result = parse_classification_result(classification_result)\n",
    "                new_groups = generate_groups_from_classification(parsed_result)\n",
    "\n",
    "                # Recursively call itself to process new subgroups, increasing the recursion depth\n",
    "                recursive_classification(new_groups, final_classification, classification_results, depth + 1, max_depth)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch exceptions and print error messages\n",
    "            print(f\"Error processing group with state: {state}, species: {current_group}, at depth: {depth}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            raise e\n",
    "\n",
    "    return final_classification"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:31:19.483549Z",
     "start_time": "2024-06-14T01:31:19.479015Z"
    }
   },
   "id": "718e25487a7fba3d",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial groups: [('1', ['Diphasiastrum alpinum', 'Diphasiastrum complanatum', 'Huperzia selago', 'Lycopodiella inundata', 'Lycopodium annotinum', 'Lycopodium clavatum', 'Selaginella kraussiana', 'Selaginella selaginoides']), ('2', ['Isoetes echinospora', 'Isoetes histrix', 'Isoetes lacustris'])]\n",
      "Initial final_classification: {}\n",
      "Initial classification_results: {}\n",
      "Processing group with state: 1, species: ['Diphasiastrum alpinum', 'Diphasiastrum complanatum', 'Huperzia selago', 'Lycopodiella inundata', 'Lycopodium annotinum', 'Lycopodium clavatum', 'Selaginella kraussiana', 'Selaginella selaginoides'], at depth: 0\n",
      "```json\n",
      "{\n",
      "    \"Character\": \"Character2\",\n",
      "    \"States\": {\n",
      "        \"1\": [\"Huperzia selago\"],\n",
      "        \"2\": {\n",
      "            \"Character\": \"Character5\",\n",
      "            \"States\": {\n",
      "                \"1\": {\n",
      "                    \"Character\": \"Character9\",\n",
      "                    \"States\": {\n",
      "                        \"1\": [\"Diphasiastrum alpinum\"],\n",
      "                        \"2\": {\n",
      "                            \"Character\": \"Character12\",\n",
      "                            \"States\": {\n",
      "                                \"1\": [\"Lycopodium clavatum\"],\n",
      "                                \"2\": {\n",
      "                                    \"Character\": \"Character20\",\n",
      "                                    \"States\": {\n",
      "                                        \"1\": [\"Lycopodiella inundata\"],\n",
      "                                        \"2\": [\"Lycopodium annotinum\"],\n",
      "                                        \"3\": [\"Lycopodium annotinum\"]\n",
      "                                    }\n",
      "                                }\n",
      "                            }\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"3\": [\"Diphasiastrum complanatum\"]\n",
      "            }\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"Character\": \"Character8\",\n",
      "            \"States\": {\n",
      "                \"1\": {\n",
      "                    \"Character\": \"Character4\",\n",
      "                    \"States\": {\n",
      "                        \"1\": [\"Selaginella kraussiana\"],\n",
      "                        \"2\": [\"Selaginella selaginoides\"]\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "Processing group with state: 1, species: ['Selaginella kraussiana'], at depth: 1\n",
      "Processing group with state: 2, species: ['Selaginella selaginoides'], at depth: 1\n",
      "Processing group with state: 3, species: ['Diphasiastrum complanatum'], at depth: 1\n",
      "Processing group with state: 2, species: ['Isoetes echinospora', 'Isoetes histrix', 'Isoetes lacustris'], at depth: 0\n",
      "Here is the nested taxonomic key in the specified JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"Character\": \"Character20\",\n",
      "    \"States\": {\n",
      "        \"1\": [\"Isoetes histrix\"],\n",
      "        \"2 and 3\": [\"Isoetes lacustris\"],\n",
      "        \"1 and 2 and 3\": [\"Isoetes echinospora\"]\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "This JSON structure represents the taxonomic key based on the provided classification results.\n",
      "Processing group with state: 1, species: ['Isoetes histrix'], at depth: 1\n",
      "Processing group with state: 2 and 3, species: ['Isoetes lacustris'], at depth: 1\n",
      "Processing group with state: 1 and 2 and 3, species: ['Isoetes echinospora'], at depth: 1\n",
      "Final Classification:\n",
      "{\n",
      "  \"Selaginella kraussiana\": [\n",
      "    \"Selaginella kraussiana\"\n",
      "  ],\n",
      "  \"Selaginella selaginoides\": [\n",
      "    \"Selaginella selaginoides\"\n",
      "  ],\n",
      "  \"Diphasiastrum complanatum\": [\n",
      "    \"Diphasiastrum complanatum\"\n",
      "  ],\n",
      "  \"Isoetes histrix\": [\n",
      "    \"Isoetes histrix\"\n",
      "  ],\n",
      "  \"Isoetes lacustris\": [\n",
      "    \"Isoetes lacustris\"\n",
      "  ],\n",
      "  \"Isoetes echinospora\": [\n",
      "    \"Isoetes echinospora\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "Classification Results:\n",
      "{'1': '{\\n    \"Character\": \"Character2\",\\n    \"States\": {\\n        \"1\": [\"Huperzia selago\"],\\n        \"2\": {\\n            \"Character\": \"Character5\",\\n            \"States\": {\\n                \"1\": {\\n                    \"Character\": \"Character9\",\\n                    \"States\": {\\n                        \"1\": [\"Diphasiastrum alpinum\"],\\n                        \"2\": {\\n                            \"Character\": \"Character12\",\\n                            \"States\": {\\n                                \"1\": [\"Lycopodium clavatum\"],\\n                                \"2\": {\\n                                    \"Character\": \"Character20\",\\n                                    \"States\": {\\n                                        \"1\": [\"Lycopodiella inundata\"],\\n                                        \"2\": [\"Lycopodium annotinum\"],\\n                                        \"3\": [\"Lycopodium annotinum\"]\\n                                    }\\n                                }\\n                            }\\n                        }\\n                    }\\n                },\\n                \"3\": [\"Diphasiastrum complanatum\"]\\n            }\\n        },\\n        \"3\": {\\n            \"Character\": \"Character8\",\\n            \"States\": {\\n                \"1\": {\\n                    \"Character\": \"Character4\",\\n                    \"States\": {\\n                        \"1\": [\"Selaginella kraussiana\"],\\n                        \"2\": [\"Selaginella selaginoides\"]\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}', '2': '{\\n    \"Character\": \"Character20\",\\n    \"States\": {\\n        \"1\": [\"Isoetes histrix\"],\\n        \"2 and 3\": [\"Isoetes lacustris\"],\\n        \"1 and 2 and 3\": [\"Isoetes echinospora\"]\\n    }\\n}'}\n"
     ]
    }
   ],
   "source": [
    "# Assume the variables have been initialized\n",
    "max_depth =  5  # Can be adjusted based on the hierarchical structure of input data and application requirements\n",
    "# here is the initial character level is about species number need to classify\n",
    "\n",
    "# Dictionary to store the final classification where each species is classified individually\n",
    "final_classification = {}\n",
    "\n",
    "# Dictionary to store the API classification results for each state\n",
    "classification_results = {}\n",
    "\n",
    "# Print the initial state of groups and dictionaries for debugging purposes\n",
    "print(\"Initial groups:\", groups)\n",
    "print(\"Initial final_classification:\", final_classification)\n",
    "print(\"Initial classification_results:\", classification_results)\n",
    "\n",
    "# Call the recursive_classification function to process the groups and store the results\n",
    "final_classification = recursive_classification(groups, final_classification, classification_results, depth=0, max_depth=max_depth)\n",
    "\n",
    "# Print the final classification results\n",
    "print(\"Final Classification:\")\n",
    "print(json.dumps(final_classification, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Print the classification results from the API calls\n",
    "print(\"\\nClassification Results:\")\n",
    "print(classification_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:53:14.753695Z",
     "start_time": "2024-06-14T01:52:49.736442Z"
    }
   },
   "id": "11d47ae207d91371",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': '{\\n    \"Character\": \"Character2\",\\n    \"States\": {\\n        \"1\": [\"Huperzia selago\"],\\n        \"2\": {\\n            \"Character\": \"Character5\",\\n            \"States\": {\\n                \"1\": {\\n                    \"Character\": \"Character9\",\\n                    \"States\": {\\n                        \"1\": [\"Diphasiastrum alpinum\"],\\n                        \"2\": {\\n                            \"Character\": \"Character12\",\\n                            \"States\": {\\n                                \"1\": [\"Lycopodium clavatum\"],\\n                                \"2\": {\\n                                    \"Character\": \"Character20\",\\n                                    \"States\": {\\n                                        \"1\": [\"Lycopodiella inundata\"],\\n                                        \"2\": [\"Lycopodium annotinum\"],\\n                                        \"3\": [\"Lycopodium annotinum\"]\\n                                    }\\n                                }\\n                            }\\n                        }\\n                    }\\n                },\\n                \"3\": [\"Diphasiastrum complanatum\"]\\n            }\\n        },\\n        \"3\": {\\n            \"Character\": \"Character8\",\\n            \"States\": {\\n                \"1\": {\\n                    \"Character\": \"Character4\",\\n                    \"States\": {\\n                        \"1\": [\"Selaginella kraussiana\"],\\n                        \"2\": [\"Selaginella selaginoides\"]\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}', '2': '{\\n    \"Character\": \"Character20\",\\n    \"States\": {\\n        \"1\": [\"Isoetes histrix\"],\\n        \"2 and 3\": [\"Isoetes lacustris\"],\\n        \"1 and 2 and 3\": [\"Isoetes echinospora\"]\\n    }\\n}'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "groups = generate_groups_from_classification(parsed_initial_classification)\n",
    "print(classification_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:53:22.341923Z",
     "start_time": "2024-06-14T01:53:22.337742Z"
    }
   },
   "id": "7f8b752c0b34ce0e",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_paths(node, path=None):\n",
    "    if path is None:\n",
    "        path = {}\n",
    "\n",
    "    if 'Character' in node and 'States' in node:\n",
    "        current_character = node['Character'].replace(\" \", \"\").strip()\n",
    "        for state, value in node['States'].items():\n",
    "            new_path = path.copy()\n",
    "            new_path[current_character] = state\n",
    "            if isinstance(value, dict):\n",
    "                yield from extract_paths(value, new_path)\n",
    "            else:\n",
    "                for species in value:\n",
    "                    yield species, new_path\n",
    "\n",
    "# Process each classification result and extract the path\n",
    "final_results = {}\n",
    "\n",
    "for key, json_str in classification_results.items():\n",
    "    classification_data = json.loads(json_str)\n",
    "    species_paths = list(extract_paths(classification_data))\n",
    "\n",
    "    formatted_results = {}\n",
    "    for species, path in species_paths:\n",
    "        formatted_results[species] = {\"Characteristics\": path}\n",
    "    \n",
    "    final_results[key] = formatted_results\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:53:58.459495Z",
     "start_time": "2024-06-14T01:53:58.455706Z"
    }
   },
   "id": "9c7c1139650cf60d",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_state_match(state, correct_state):\n",
    "    if correct_state is None:\n",
    "        return False\n",
    "    if \" and \" in correct_state:\n",
    "        correct_states = correct_state.split(\" and \")\n",
    "        return all(sub_state in correct_states for sub_state in state.split(\" and \"))\n",
    "    return state == correct_state\n",
    "\n",
    "# Validate classification results and log errors\n",
    "def validate_results(final_results, knowledge_graph):\n",
    "    errors = []\n",
    "    for key, results in final_results.items():\n",
    "        for species, data in results.items():\n",
    "            if species in knowledge_graph:\n",
    "                mismatch = False\n",
    "                incorrect_character_states = {}\n",
    "                for character, state in data[\"Characteristics\"].items():\n",
    "                    character = character.replace(\" \", \"\").strip()\n",
    "                    correct_state = knowledge_graph[species][\"Characteristics\"].get(character)\n",
    "                    if correct_state is None or not check_state_match(state, correct_state):\n",
    "                        mismatch = True\n",
    "                        incorrect_character_states[character] = {\"error_state\": state, \"correct_state\": correct_state}\n",
    "                if mismatch:\n",
    "                    errors.append({\n",
    "                        \"species\": species,\n",
    "                        \"key\": key,\n",
    "                        \"error\": \"Mismatch\",\n",
    "                        \"error_result\": incorrect_character_states,\n",
    "                        \"correct_result\": {character: knowledge_graph[species][\"Characteristics\"].get(character) for character in incorrect_character_states}\n",
    "                    })\n",
    "            else:\n",
    "                errors.append({\n",
    "                    \"species\": species,\n",
    "                    \"key\": key,\n",
    "                    \"error\": \"Species not found in knowledge graph\",\n",
    "                    \"error_result\": data[\"Characteristics\"]\n",
    "                })\n",
    "    return errors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:54:00.305568Z",
     "start_time": "2024-06-14T01:54:00.300385Z"
    }
   },
   "id": "6cab39ffea0bbc52",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_species_list_for_state(groups, key):\n",
    "    species_list = []\n",
    "    for state, species in groups:\n",
    "        if state == key:\n",
    "            species_list = species\n",
    "            break\n",
    "    if not species_list:\n",
    "        print(f\"Key {key} not found in groups\")\n",
    "    else:\n",
    "        print(f\"Processing species list for state '{key}': {species_list}\")\n",
    "    return species_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:54:02.714754Z",
     "start_time": "2024-06-14T01:54:02.710476Z"
    }
   },
   "id": "53217216d446d56a",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def correct_classification(errors, classification_results, knowledge_graph):\n",
    "    for error in errors:\n",
    "        key = error['key']\n",
    "        \n",
    "        species_list = get_species_list_for_state(groups, key)\n",
    "        if not species_list:\n",
    "            continue\n",
    "        \n",
    "        group_matrix = {s: knowledge_graph[s] for s in species_list}\n",
    "        group_matrix_str = json.dumps(group_matrix, ensure_ascii=False)  \n",
    "        \n",
    "        messages2 = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": \"\"\"\n",
    "             You are a helpful taxonomist assistant.\n",
    "             You are skilled at calculating the correct information gain to choose the character that best divides species into even groups based on their states.\n",
    "             Based on the selected character, classify the species into different groups according to their states.\n",
    "             For each group with more than two species, continue selecting characters to further classify this group until each group only has one species.\n",
    "             After multiple classifications, determine the final classification levels and record each classifying character and its state.\n",
    "             Finally, generate a taxonomic key.\n",
    "             You are able to avoid the same error in your results based on the corrected results previously passed to you\n",
    "             ***IMPORTANT: Ensure that each group contains only one species in the final classification result. don't appear the result like state :[species A, species B]***\n",
    "             \"\"\"},\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": \"\"\"\n",
    "             Generate the nested taxonomic key based on the provided morphological matrix.\n",
    "             The process involves selecting a character to classify the species into groups. Repeat this classification within each subgroup until each group contains only one species.\n",
    "             Information gain measures how much the uncertainty in the dataset is reduced after using a character for classification. It helps in selecting characters that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "             Please select the classification character for these group's species based on the morphological matrix and information gain methods.\n",
    "             In the morphological matrix, 'Missing' and 'Not applicable' are invalid states. If a character has invalid states for the group being classified, it should be ignored.\n",
    "             States are represented by numbers. For example, '1 and 2' means multiple states should be treated as a single state type and this multi-state characterization should not be confused with the single states within it (the state of '3' and '2 and 3' is different state, when you choose the character to based on the state to distinguish need to careful handle). The initial character should have no more than three state types.\n",
    "             You need to calculate the information gain for each character and choose the highest information gain result. The higher the information gain result, the greater the contribution of the feature to the classification.\n",
    "             After selecting the initial classification character and categorizing the species based on its state, repeat the process within each subgroup. For each subgroup, select the character with the highest information gain to further classify the species. Continue this process recursively until each group contains only one species.\n",
    "             in the results, each group only allow one species, need to choose suitable character\n",
    "             Now I will show you the morphological matrix. Please provide the classification character and the categorization of species based on its state. Then, continue to classify each subgroup recursively, showing the chosen character and categorization for each subgroup. Please present the result in a structured format, with each step clearly labeled.\n",
    "             Please don't show how you analyze and calculate, please show me the final result.\n",
    "             \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            This is the result of the error you generated in the previous API call. \n",
    "            In this file I have provided you with the CORRECT result. \n",
    "            Please strictly adhere to the use of the correct species feature status message!{error}\n",
    "            \"\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"\"\"\n",
    "            I will strictly use the correct species feature state information for evaluation, \n",
    "            while I will avoid using these incorrect feature state information that appeared previously in the classification results\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here is the group information need to be classify and include the morphological matrix {group_matrix_str}\"}\n",
    "        ]\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages2,\n",
    "            stop=None,\n",
    "            temperature=0,\n",
    "            max_tokens=1000,\n",
    "            n=1\n",
    "        )\n",
    "        corrected_result = response.choices[0].message.content\n",
    "        \n",
    "        messages_JSON = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             You are a helpful JSON format converter.\n",
    "             You can express the nested structure as a JSON result based on the corresponding content.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Please format the classification result as follows:\n",
    "             ```\n",
    "             # Final taxonomic key result JSON format #\n",
    "             {\n",
    "                 \"Character\": \"CharacterX\",\n",
    "                 \"States\": {\n",
    "                     \"1\": [\"speciesA\"],\n",
    "                     \"2\": {\n",
    "                         \"Character\": \"CharacterY\",\n",
    "                         \"States\": {\n",
    "                             \"1\": [\"speciesB\"],\n",
    "                             \"2\": [\"speciesC\"]\n",
    "                         }\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "             ```\n",
    "             Ensure that the response follows this format exactly.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Understood. I'll convert the nested structure you gave me into JSON format and store it in # final result #.\n",
    "             Please provide what you need to convert the format.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here are the taxonomic results for the nested schema representation {corrected_result}\"}\n",
    "        ]\n",
    "    \n",
    "        # Make the API call to format the response as JSON\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages_JSON,\n",
    "            stop=None,\n",
    "            temperature=0,\n",
    "            max_tokens=1500,\n",
    "            n=1\n",
    "        )\n",
    "        json_result = response.choices[0].message.content\n",
    "        json_cleaned_result = extract_json_string(json_result)\n",
    "        print(json_cleaned_result)\n",
    "        classification_results[key] = json_cleaned_result\n",
    "        return classification_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:54:05.739622Z",
     "start_time": "2024-06-14T01:54:05.733944Z"
    }
   },
   "id": "e895eee68fca094b",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': '{\\n    \"Character\": \"Character2\",\\n    \"States\": {\\n        \"1\": [\"Huperzia selago\"],\\n        \"2\": {\\n            \"Character\": \"Character5\",\\n            \"States\": {\\n                \"1\": {\\n                    \"Character\": \"Character9\",\\n                    \"States\": {\\n                        \"1\": [\"Diphasiastrum alpinum\"],\\n                        \"2\": {\\n                            \"Character\": \"Character12\",\\n                            \"States\": {\\n                                \"1\": [\"Lycopodium clavatum\"],\\n                                \"2\": {\\n                                    \"Character\": \"Character20\",\\n                                    \"States\": {\\n                                        \"1\": [\"Lycopodiella inundata\"],\\n                                        \"2\": [\"Lycopodium annotinum\"],\\n                                        \"3\": [\"Lycopodium annotinum\"]\\n                                    }\\n                                }\\n                            }\\n                        }\\n                    }\\n                },\\n                \"3\": [\"Diphasiastrum complanatum\"]\\n            }\\n        },\\n        \"3\": {\\n            \"Character\": \"Character8\",\\n            \"States\": {\\n                \"1\": {\\n                    \"Character\": \"Character4\",\\n                    \"States\": {\\n                        \"1\": [\"Selaginella kraussiana\"],\\n                        \"2\": [\"Selaginella selaginoides\"]\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}', '2': '{\\n    \"Character\": \"Character20\",\\n    \"States\": {\\n        \"1\": [\"Isoetes histrix\"],\\n        \"2 and 3\": [\"Isoetes lacustris\"],\\n        \"1 and 2 and 3\": [\"Isoetes echinospora\"]\\n    }\\n}'}\n"
     ]
    }
   ],
   "source": [
    "print(classification_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:54:09.357919Z",
     "start_time": "2024-06-14T01:54:09.355058Z"
    }
   },
   "id": "eef2728d0fb03335",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing species list for state '1': ['Diphasiastrum alpinum', 'Diphasiastrum complanatum', 'Huperzia selago', 'Lycopodiella inundata', 'Lycopodium annotinum', 'Lycopodium clavatum', 'Selaginella kraussiana', 'Selaginella selaginoides']\n",
      "{\n",
      "    \"Character\": \"Character2\",\n",
      "    \"States\": {\n",
      "        \"1\": [\"Huperzia selago\"],\n",
      "        \"2\": {\n",
      "            \"Character\": \"Character5\",\n",
      "            \"States\": {\n",
      "                \"1\": {\n",
      "                    \"Character\": \"Character20\",\n",
      "                    \"States\": {\n",
      "                        \"1\": [\"Lycopodiella inundata\"],\n",
      "                        \"2 and 3\": [\"Lycopodium annotinum\"],\n",
      "                        \"1 and 2 and 3\": [\"Lycopodium clavatum\"]\n",
      "                    }\n",
      "                },\n",
      "                \"2\": [\"Diphasiastrum alpinum\"],\n",
      "                \"3\": [\"Diphasiastrum complanatum\"]\n",
      "            }\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"Character\": \"Character8\",\n",
      "            \"States\": {\n",
      "                \"1\": [\"Selaginella kraussiana\"],\n",
      "                \"2\": [\"Selaginella selaginoides\"]\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Processing species list for state '1': ['Diphasiastrum alpinum', 'Diphasiastrum complanatum', 'Huperzia selago', 'Lycopodiella inundata', 'Lycopodium annotinum', 'Lycopodium clavatum', 'Selaginella kraussiana', 'Selaginella selaginoides']\n",
      "{\n",
      "    \"Character\": \"Character2\",\n",
      "    \"States\": {\n",
      "        \"1\": [\"Huperzia selago\"],\n",
      "        \"2\": {\n",
      "            \"Character\": \"Character12\",\n",
      "            \"States\": {\n",
      "                \"1\": [\"Lycopodium clavatum\"],\n",
      "                \"2\": {\n",
      "                    \"Character\": \"Character9\",\n",
      "                    \"States\": {\n",
      "                        \"1\": {\n",
      "                            \"Character\": \"Character5\",\n",
      "                            \"States\": {\n",
      "                                \"2\": [\"Diphasiastrum alpinum\"],\n",
      "                                \"3\": [\"Diphasiastrum complanatum\"]\n",
      "                            }\n",
      "                        },\n",
      "                        \"2\": {\n",
      "                            \"Character\": \"Character20\",\n",
      "                            \"States\": {\n",
      "                                \"1\": [\"Lycopodiella inundata\"],\n",
      "                                \"2 and 3\": [\"Lycopodium annotinum\"]\n",
      "                            }\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"Character\": \"Character8\",\n",
      "            \"States\": {\n",
      "                \"1\": {\n",
      "                    \"Character\": \"Character4\",\n",
      "                    \"States\": {\n",
      "                        \"1\": [\"Selaginella kraussiana\"],\n",
      "                        \"2\": [\"Selaginella selaginoides\"]\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Final classification results have been saved to 'final_classification.json'.\n",
      "{\n",
      "    \"1\": {\n",
      "        \"Huperzia selago\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Lycopodium clavatum\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"2\",\n",
      "                \"Character12\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Diphasiastrum alpinum\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"2\",\n",
      "                \"Character12\": \"2\",\n",
      "                \"Character9\": \"1\",\n",
      "                \"Character5\": \"2\"\n",
      "            }\n",
      "        },\n",
      "        \"Diphasiastrum complanatum\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"2\",\n",
      "                \"Character12\": \"2\",\n",
      "                \"Character9\": \"1\",\n",
      "                \"Character5\": \"3\"\n",
      "            }\n",
      "        },\n",
      "        \"Lycopodiella inundata\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"2\",\n",
      "                \"Character12\": \"2\",\n",
      "                \"Character9\": \"2\",\n",
      "                \"Character20\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Lycopodium annotinum\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"2\",\n",
      "                \"Character12\": \"2\",\n",
      "                \"Character9\": \"2\",\n",
      "                \"Character20\": \"2 and 3\"\n",
      "            }\n",
      "        },\n",
      "        \"Selaginella kraussiana\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"3\",\n",
      "                \"Character8\": \"1\",\n",
      "                \"Character4\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Selaginella selaginoides\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"3\",\n",
      "                \"Character8\": \"1\",\n",
      "                \"Character4\": \"2\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"Isoetes histrix\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character20\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Isoetes lacustris\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character20\": \"2 and 3\"\n",
      "            }\n",
      "        },\n",
      "        \"Isoetes echinospora\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character20\": \"1 and 2 and 3\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Cycle checks and corrections\n",
    "errors = validate_results(final_results, knowledge_graph)\n",
    "# Purpose: Enter a loop until all errors have been fixed.\n",
    "# Function: Executes the code inside the loop when the errors list is not empty.\n",
    "while errors:\n",
    "    # Fix current categorization errors. (based on the API )\n",
    "    classification_results = correct_classification(errors, classification_results, knowledge_graph)\n",
    "    # Purpose: To reset the final_results dictionary to store the corrected categorization results.\n",
    "    final_results = {}\n",
    "    # Iterate over the corrected classification results and extract species classification paths.\n",
    "    for key, json_str in classification_results.items():\n",
    "        classification_data = json.loads(json_str)\n",
    "        species_paths = list(extract_paths(classification_data))\n",
    "        # Purpose: Format the extracted classification paths and store them in the formatted_results dictionary.\n",
    "        formatted_results = {}\n",
    "        for species, path in species_paths:\n",
    "            formatted_results[species] = {\"Characteristics\": path}\n",
    "        # Purpose: Add the formatted classification results to final_results.\n",
    "        final_results[key] = formatted_results\n",
    "    # Purpose: Re-validate the corrected classification results and log any remaining errors.\n",
    "    # Function: Call the validate_results function, passing in the updated final_results and knowledge_graph and returning a new list of errors. If there are no errors, then errors is empty and the loop ends.\n",
    "    errors = validate_results(final_results, knowledge_graph)\n",
    "\n",
    "# Save the final classification results\n",
    "with open('final_classification.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=4)\n",
    "print(\"Final classification results have been saved to 'final_classification.json'.\")\n",
    "print(json.dumps(final_results, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T01:54:45.994506Z",
     "start_time": "2024-06-14T01:54:13.638294Z"
    }
   },
   "id": "703e027a845beefd",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': '{\\n    \"Character\": \"Character2\",\\n    \"States\": {\\n        \"1\": [\"Huperzia selago\"],\\n        \"2\": {\\n            \"Character\": \"Character12\",\\n            \"States\": {\\n                \"1\": [\"Lycopodium clavatum\"],\\n                \"2\": {\\n                    \"Character\": \"Character9\",\\n                    \"States\": {\\n                        \"1\": {\\n                            \"Character\": \"Character5\",\\n                            \"States\": {\\n                                \"2\": [\"Diphasiastrum alpinum\"],\\n                                \"3\": [\"Diphasiastrum complanatum\"]\\n                            }\\n                        },\\n                        \"2\": {\\n                            \"Character\": \"Character20\",\\n                            \"States\": {\\n                                \"1\": [\"Lycopodiella inundata\"],\\n                                \"2 and 3\": [\"Lycopodium annotinum\"]\\n                            }\\n                        }\\n                    }\\n                }\\n            }\\n        },\\n        \"3\": {\\n            \"Character\": \"Character8\",\\n            \"States\": {\\n                \"1\": {\\n                    \"Character\": \"Character4\",\\n                    \"States\": {\\n                        \"1\": [\"Selaginella kraussiana\"],\\n                        \"2\": [\"Selaginella selaginoides\"]\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}', '2': '{\\n    \"Character\": \"Character20\",\\n    \"States\": {\\n        \"1\": [\"Isoetes histrix\"],\\n        \"2 and 3\": [\"Isoetes lacustris\"],\\n        \"1 and 2 and 3\": [\"Isoetes echinospora\"]\\n    }\\n}'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(classification_results)\n",
    "print(type(classification_results))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T02:20:15.563396Z",
     "start_time": "2024-06-14T02:20:15.559082Z"
    }
   },
   "id": "4c10fe8f96d30f1f",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(character_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T03:45:50.751409Z",
     "start_time": "2024-06-14T03:45:50.749151Z"
    }
   },
   "id": "a45183524d928dbc",
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Classification Key:\n",
      "{\n",
      "    \"Character 1: stems <elongation>\": {\n",
      "        \"State 1: elongated, with numerous small\": {\n",
      "            \"Character 2: stems <carriage>\": {\n",
      "                \"State 1: suberect, and rooting at the b\": \"Huperzia selago\",\n",
      "                \"State 2: creeping, and rooting directly\": {\n",
      "                    \"Character 12: leaves <whether hair-pointed>\": {\n",
      "                        \"State 1: with long, filiform hair-like\": \"Lycopodium clavatum\",\n",
      "                        \"State 2: not hair-pointed\": {\n",
      "                            \"Character 9: leaves <arrangement>\": {\n",
      "                                \"State 1: 4-ranked on the branches\": {\n",
      "                                    \"Character 5: stems <whether with flattened\": {\n",
      "                                        \"State 2: with only slightly flattened b\": \"Diphasiastrum alpinum\",\n",
      "                                        \"State 3: with strongly flattened branch\": \"Diphasiastrum complanatum\"\n",
      "                                    }\n",
      "                                },\n",
      "                                \"State 2: not 4-ranked\": {\n",
      "                                    \"Character 20: <habitat elevation:>\": {\n",
      "                                        \"State 1: lowland\": \"Lycopodiella inundata\",\n",
      "                                        \"State 2 and 3: upland /  / montane\": \"Lycopodium annotinum\"\n",
      "                                    }\n",
      "                                }\n",
      "                            }\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"State 3: creeping, and rooting from cha\": {\n",
      "                    \"Character 8: leaves <whether ligulate>\": {\n",
      "                        \"State 1: ligulate\": {\n",
      "                            \"Character 4: stems <whether dorsiventral>\": {\n",
      "                                \"State 1: dorsiventrally organized, with\": \"Selaginella kraussiana\",\n",
      "                                \"State 2: not dorsiventrally organized\": \"Selaginella selaginoides\"\n",
      "                            }\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"State 2: short and tuberous, with sheat\": {\n",
      "            \"Character 20: <habitat elevation:>\": {\n",
      "                \"State 1: lowland\": \"Isoetes histrix\",\n",
      "                \"State 2 and 3: upland /  / montane\": \"Isoetes lacustris\",\n",
      "                \"State 1 and 2 and 3: lowland /  / upland /  / montane\": \"Isoetes echinospora\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classification_result = {key: json.loads(value) for key, value in classification_results.items()}\n",
    "\n",
    "# Recursive function converts the structure into the desired format\n",
    "def convert_structure(node):\n",
    "    if \"Character\" in node and \"States\" in node:\n",
    "        character = node[\"Character\"]\n",
    "        states = node[\"States\"]\n",
    "        converted = {f\"Character {character.replace('Character', '')}\": {}}\n",
    "        for state, sub_node in states.items():\n",
    "            state_key = f\"State {state}\"\n",
    "            if isinstance(sub_node, list):\n",
    "                converted[f\"Character {character.replace('Character', '')}\"][state_key] = sub_node[0] if len(sub_node) == 1 else sub_node\n",
    "            elif isinstance(sub_node, dict):\n",
    "                converted[f\"Character {character.replace('Character', '')}\"][state_key] = convert_structure(sub_node)\n",
    "        return converted\n",
    "    return node\n",
    "\n",
    "# Processing Classification Retrieval Table\n",
    "converted_result = {}\n",
    "for key, value in classification_result.items():\n",
    "    converted_result[f\"Character {key}\"] = convert_structure(value)\n",
    "\n",
    "# Integration of initial categorization with other results\n",
    "def combine_results(initial, secondary, state_key):\n",
    "    if not secondary:\n",
    "        return\n",
    "\n",
    "    initial_states = initial[\"States\"].get(state_key)\n",
    "    if initial_states is None:\n",
    "        initial[\"States\"][state_key] = secondary\n",
    "        return\n",
    "\n",
    "    if isinstance(initial_states, list):\n",
    "        if isinstance(secondary, list):\n",
    "            initial[\"States\"][state_key] = list(set(initial_states + secondary))  # 合并两个列表并去重\n",
    "        else:\n",
    "            initial[\"States\"][state_key] = secondary\n",
    "    elif isinstance(initial_states, dict):\n",
    "        if isinstance(secondary, dict):\n",
    "            for key, value in secondary[\"States\"].items():\n",
    "                if key not in initial_states:\n",
    "                    initial_states[key] = value\n",
    "                else:\n",
    "                    combine_results(initial_states, value, key)\n",
    "        else:\n",
    "            raise ValueError(f\"冲突的类型，键 {state_key}: {type(initial_states)} vs {type(secondary)}\")\n",
    "    else:\n",
    "        raise ValueError(f\"初始状态的意外类型: {type(initial_states)}\")\n",
    "\n",
    "# Dynamic consolidation of all sub-categorized results\n",
    "for state_key, secondary in classification_result.items():\n",
    "    combine_results(parsed_initial_classification, secondary, state_key)\n",
    "\n",
    "# Convert the merged result into the desired format\n",
    "converted_initial_classification = convert_structure(parsed_initial_classification)\n",
    "\n",
    "# Recursive Function Replacement Characterization and State Description\n",
    "def replace_indices_with_descriptions_in_key(key, character_info, parent_char_index=None):\n",
    "    updated_key = {}\n",
    "    for char_state, subtree in key.items():\n",
    "        if char_state.startswith(\"Character\"):\n",
    "            parts = char_state.split()\n",
    "            if len(parts) > 1:\n",
    "                char_index = parts[1]\n",
    "                if char_index in character_info:\n",
    "                    char_description = f\"Character {char_index}: {character_info[char_index]['description']}\"\n",
    "                    if isinstance(subtree, dict):\n",
    "                        updated_subtree = replace_indices_with_descriptions_in_key(subtree, character_info, char_index)\n",
    "                        updated_key[char_description] = updated_subtree\n",
    "                    else:\n",
    "                        updated_key[char_description] = subtree\n",
    "                else:\n",
    "                    updated_key[char_state] = subtree\n",
    "            else:\n",
    "                updated_key[char_state] = subtree\n",
    "        elif char_state.startswith(\"State\") and parent_char_index:\n",
    "            states = char_state.split()[1:]\n",
    "            state_descriptions = []\n",
    "            for state in states:\n",
    "                individual_states = state.split(\"and\")\n",
    "                descriptions = [character_info[parent_char_index][\"states\"].get(s.strip(), \"\") for s in individual_states]\n",
    "                state_descriptions.append(\" and \".join(filter(None, descriptions)))\n",
    "            state_key = f\"State {' '.join(states)}: {' / '.join(state_descriptions)}\"\n",
    "            if isinstance(subtree, dict):\n",
    "                updated_key[state_key] = replace_indices_with_descriptions_in_key(subtree, character_info, parent_char_index)\n",
    "            else:\n",
    "                updated_key[state_key] = subtree\n",
    "        else:\n",
    "            updated_key[char_state] = subtree\n",
    "    return updated_key\n",
    "\n",
    "# Replacement characterization and state description\n",
    "updated_classification_key = replace_indices_with_descriptions_in_key(converted_initial_classification, character_info)\n",
    "\n",
    "# Print the updated categorized search form\n",
    "print(\"Updated Classification Key:\")\n",
    "print(json.dumps(updated_classification_key, indent=4, ensure_ascii=False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T03:49:36.149710Z",
     "start_time": "2024-06-14T03:49:36.139936Z"
    }
   },
   "id": "4c5e9c27edc2016d",
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Character1:**\n",
      "   - State \"1\":\n",
      "    1. **Character2:**\n",
      "       - State \"1\": Huperzia selago\n",
      "       - State \"2\":\n",
      "        1. **Character12:**\n",
      "           - State \"1\": Lycopodium clavatum\n",
      "           - State \"2\":\n",
      "            1. **Character9:**\n",
      "               - State \"1\":\n",
      "                1. **Character5:**\n",
      "                   - State \"2\": Diphasiastrum alpinum\n",
      "                   - State \"3\": Diphasiastrum complanatum\n",
      "               - State \"2\":\n",
      "                1. **Character20:**\n",
      "                   - State \"1\": Lycopodiella inundata\n",
      "                   - State \"2 and 3\": Lycopodium annotinum\n",
      "       - State \"3\":\n",
      "        1. **Character8:**\n",
      "           - State \"1\":\n",
      "            1. **Character4:**\n",
      "               - State \"1\": Selaginella kraussiana\n",
      "               - State \"2\": Selaginella selaginoides\n",
      "   - State \"2\":\n",
      "    1. **Character20:**\n",
      "       - State \"1\": Isoetes histrix\n",
      "       - State \"2 and 3\": Isoetes lacustris\n",
      "       - State \"1 and 2 and 3\": Isoetes echinospora\n"
     ]
    }
   ],
   "source": [
    "# Example initial result\n",
    "initial_result = parsed_initial_classification\n",
    "\n",
    "# Parse the API response JSON strings\n",
    "parsed_classification_results = {key: json.loads(value) for key, value in classification_results.items()}\n",
    "\n",
    "# Function to combine the initial and secondary classification results\n",
    "def combine_results(initial, secondary, state_key):\n",
    "    if not secondary:\n",
    "        return\n",
    "\n",
    "    initial_states = initial[\"States\"].get(state_key)\n",
    "    if initial_states is None:\n",
    "        initial[\"States\"][state_key] = secondary\n",
    "        return\n",
    "\n",
    "    if isinstance(initial_states, list):\n",
    "        if isinstance(secondary, list):\n",
    "            initial[\"States\"][state_key] = list(set(initial_states + secondary))  # Merge two lists and remove duplicates\n",
    "        else:\n",
    "            initial[\"States\"][state_key] = secondary\n",
    "    elif isinstance(initial_states, dict):\n",
    "        if isinstance(secondary, dict):\n",
    "            for key, value in secondary[\"States\"].items():\n",
    "                if key not in initial_states:\n",
    "                    initial_states[key] = value\n",
    "                else:\n",
    "                    combine_results(initial_states, value, key)\n",
    "        else:\n",
    "            raise ValueError(f\"Conflicting types for key {state_key}: {type(initial_states)} vs {type(secondary)}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected type for initial states: {type(initial_states)}\")\n",
    "\n",
    "# Dynamically combine all secondary classification results\n",
    "for state_key, secondary in parsed_classification_results.items():\n",
    "    combine_results(initial_result, secondary, state_key)\n",
    "\n",
    "# Function to display the final classification result\n",
    "def display_classification(result, indent=0):\n",
    "    indent_space = \" \" * indent\n",
    "    character = result.get(\"Character\")\n",
    "    states = result.get(\"States\")\n",
    "\n",
    "    classification = {}\n",
    "    if character and states:\n",
    "        classification[\"Character\"] = character\n",
    "        classification[\"States\"] = {}\n",
    "        print(f\"{indent_space}1. **{character}:**\")\n",
    "        for state, species in states.items():\n",
    "            if isinstance(species, list):\n",
    "                print(f\"{indent_space}   - State \\\"{state}\\\": {', '.join(species)}\")\n",
    "                classification[\"States\"][state] = species\n",
    "            elif isinstance(species, dict):\n",
    "                print(f\"{indent_space}   - State \\\"{state}\\\":\")\n",
    "                classification[\"States\"][state] = display_classification(species, indent + 4)\n",
    "    return classification\n",
    "\n",
    "# Display the final classification result\n",
    "final_result = display_classification(initial_result)\n",
    "# print(\"\\nFinal Result JSON:\")\n",
    "# print(json.dumps(final_result, indent=2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T03:49:44.545353Z",
     "start_time": "2024-06-14T03:49:44.538284Z"
    }
   },
   "id": "fe91254cdf2ef13d",
   "execution_count": 126
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
