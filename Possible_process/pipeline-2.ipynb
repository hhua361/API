{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T06:28:38.456559Z",
     "start_time": "2024-06-12T06:28:38.452702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import json  # For handling JSON data\n",
    "from openai import OpenAI  # For interacting with OpenAI API\n",
    "import os  # For interacting with the operating system, such as file paths\n",
    "import re  # For regular expressions, useful for pattern matching in strings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file with encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "# Function to convert letter to number\n",
    "def letter_to_number(letter):\n",
    "    return str(ord(letter) - ord('A') + 10)\n",
    "\n",
    "# Function to parse matrix content\n",
    "def parse_matrix(matrix_content):\n",
    "    data = []\n",
    "    headers = []\n",
    "    lines = matrix_content.strip().split('\\n')\n",
    "    for i in range(0, len(lines), 2):\n",
    "        taxa = lines[i].strip().strip(\"'\")\n",
    "        traits = lines[i + 1].strip()\n",
    "        species_traits = []\n",
    "        j = 0\n",
    "        while j < len(traits):\n",
    "            if traits[j] == '(':\n",
    "                j += 1\n",
    "                states = ''\n",
    "                while traits[j] != ')':\n",
    "                    if traits[j].isalpha():\n",
    "                        states += letter_to_number(traits[j])\n",
    "                    else:\n",
    "                        states += traits[j]\n",
    "                    j += 1\n",
    "                species_traits.append(','.join(states))\n",
    "            elif traits[j] == '?':\n",
    "                species_traits.append('Missing')\n",
    "            elif traits[j] == '-':\n",
    "                species_traits.append('Not Applicable')\n",
    "            elif traits[j].isalpha():\n",
    "                species_traits.append(letter_to_number(traits[j]))\n",
    "            else:\n",
    "                species_traits.append(traits[j])\n",
    "            j += 1\n",
    "        data.append([taxa] + species_traits)\n",
    "    max_traits = max(len(row) - 1 for row in data)\n",
    "    headers = ['taxa'] + [f'Character{i + 1}' for i in range(max_traits)]\n",
    "    try:\n",
    "        df = pd.DataFrame(data, columns=headers)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to convert NEXUS to CSV\n",
    "def convert_nexus_to_csv(file_path, output_path):\n",
    "    try:\n",
    "        encodings = ['utf-8', 'gbk', 'latin1']  # List of encodings to try\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding=encoding) as file:\n",
    "                    content = file.read()\n",
    "                print(f\"Successfully read file with encoding: {encoding}\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Failed to read file with encoding: {encoding}\")\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError(\"Failed to read file with all attempted encodings.\")\n",
    "        \n",
    "        matrix_content = re.search(r'MATRIX\\s*(.*?)\\s*;', content, re.DOTALL).group(1).strip()\n",
    "        df = parse_matrix(matrix_content)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Appear error：{e}\")\n",
    "\n",
    "# Function to build knowledge graph from CSV\n",
    "def build_knowledge_graph(matrix):\n",
    "    knowledge_graph = {}\n",
    "    for _, row in matrix.iterrows():\n",
    "        taxa = row.iloc[0]\n",
    "        characteristics = {}\n",
    "        for col in matrix.columns[1:]:\n",
    "            state = row[col]\n",
    "            if isinstance(state, str) and ',' in state:\n",
    "                state = state.replace(',', ' and ')\n",
    "            characteristics[col] = str(state)\n",
    "        knowledge_graph[taxa] = {'Characteristics': characteristics}\n",
    "    return knowledge_graph\n",
    "\n",
    "# Function to save knowledge graph as JSON\n",
    "def save_knowledge_graph_as_json(knowledge_graph, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(knowledge_graph, f, indent=4)\n",
    "\n",
    "# Main function to combine all steps\n",
    "def nexus_to_knowledge_graph(nexus_file_path, csv_output_path, json_output_path):\n",
    "    # Step 1: Convert NEXUS to CSV\n",
    "    df = convert_nexus_to_csv(nexus_file_path, csv_output_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Step 2: Build the knowledge graph from the DataFrame\n",
    "        knowledge_graph = build_knowledge_graph(df)\n",
    "        \n",
    "        # Step 3: Save the knowledge graph as a JSON file\n",
    "        save_knowledge_graph_as_json(knowledge_graph, json_output_path)\n",
    "        \n",
    "        # Optional: Print the JSON structure for verification\n",
    "        knowledge_graph_json = json.dumps(knowledge_graph, indent=4)\n",
    "        # print(knowledge_graph_json)\n",
    "        \n",
    "        # Return the knowledge graph for further use\n",
    "        return knowledge_graph\n",
    "    else:\n",
    "        print(\"Failed to create the DataFrame from NEXUS file.\")\n",
    "        return None\n",
    "\n",
    "# Example Usage\n",
    "nexus_file_path = \"D:/桌面/taxonomy_primary_result/The_GPT-4_result/Dataset_10 (Revision of the Oriental genera of Agathidina) 18/Information gain methods/nexdata\"\n",
    "csv_output_path = \"D:/桌面/process_data_2.csv\"\n",
    "json_output_path = \"D:/桌面/knowledge_graph.json\"\n",
    "# Process the file and get the knowledge graph\n",
    "knowledge_graph = nexus_to_knowledge_graph(nexus_file_path, csv_output_path, json_output_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T06:30:09.070598Z",
     "start_time": "2024-06-12T06:30:09.047967Z"
    }
   },
   "id": "91e8e0ed78d47d3b",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initial Character Classify Result #\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Character\": \"Character1\",\n",
      "    \"States\": {\n",
      "        \"1\": [\"Biroia\", \"Coccygidium\", \"Disophrys\", \"Cremnoptoides\"],\n",
      "        \"2\": [\"Troticus\", \"Hypsostypos\", \"Cremnops\"],\n",
      "        \"3\": [\"Gyrochus\"],\n",
      "        \"4\": [\"Agathis\", \"Lytopylus\", \"Braunsia\", \"Camptothlipsis\", \"Therophilus\", \"Bassus\", \"Earinus\", \"Amputostypos\", \"Euagathis\", \"Aneurobracon\"]\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Input the API key and morphological matrix\n",
    "# Initialize the OpenAI client with the API key from environment variables\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "# This code sets up the prompt for the API input using the client.chat.completions.create interface\n",
    "# to conduct multi-turn conversations. By assigning different roles in the conversation (user, assistant, system),\n",
    "# all input information is fully conveyed to the API model.\n",
    "messages_initial = [\n",
    "    # Set the system role to focus on taxonomy tasks.\n",
    "    # Emphasize the system's understanding of morphological matrices, information gain,\n",
    "    # and the construction of classification keys in the system setup.\n",
    "    {\"role\": \"system\",\n",
    "     \"content\":\n",
    "         \"\"\"You are a helpful taxonomist assistant.\n",
    "         You are skilled at calculating the correct information gain to choose the character that best divides species into even groups based on their states.\n",
    "         Based on the selected character, classify the species into different groups according to their states.\n",
    "         For each group with more than two species, continue selecting characters to further classify this group until each group only has one species.\n",
    "         After multiple classifications, determine the final classification levels and record each classifying character and its state. \n",
    "         Finally, generate a taxonomic key.\n",
    "         Please format the classification result as follows:\n",
    "        ```\n",
    "        {\n",
    "            \"Character\": \"Character1\",\n",
    "            \"States\": {\n",
    "                \"State 1\": [\"species1\", \"species2\", ...],\n",
    "                \"State 2\": [\"species3\", \"species4\", ...],\n",
    "                \"State ...\": [\"species5\", \"species6\", ...]\n",
    "            }\n",
    "        }\n",
    "        ```\n",
    "        Ensure that the response follows this format exactly.\n",
    "        Additionally,exactly ensure that all species are included in the initial classification result.\n",
    "         \"\"\"},\n",
    "\n",
    "    # Input the main task request, construct the classification key, and emphasize the details needed for classification.\n",
    "    # This includes: the main objective, information gain calculation, ignoring invalid states, clarifying multi-character states,\n",
    "    # guiding correct selection based on the significance of information gain, and standardizing the final output format for subsequent extraction of API results.\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"\"\"\n",
    "                Generate the taxonomic key based on the provided morphological matrix. The matrix includes all species and their different states for each character.\n",
    "                The process involves selecting a character to classify the species into groups. Repeat this classification within each subgroup until each group contains only one species.\n",
    "                Information gain measures how much the uncertainty in the dataset is reduced after using a character for classification. It helps in selecting characters that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "                Please select the initial classification character for all species based on the morphological matrix and information gain methods.\n",
    "                In the morphological matrix, 'Missing' and 'Not applicable' are invalid states. If a character has invalid states for the group being classified, it should be ignored.\n",
    "                States are represented by numbers, and like the '1 and 2' means multiple states should be treated as a single state type.(such as '3' and '2 and 3'  is the different state, these are two separate states, when i choose character to based on different state to distinguish the species)\n",
    "                You need to calculate the information gain for each character, and choose the highest information gain result, The higher the Information Gain result, the greater the contribution of the feature to the classification.\n",
    "                Now I will show you the morphological matrix. Please provide only the initial classification character and the categorization of species based on its state, and you should singly show this called as # initial character classify result #\n",
    "            \"\"\"},\n",
    "\n",
    "    # Use the assistant to summarize and refine the prompt content for the API.\n",
    "    # Through the conversation with the assistant, deepen the API understanding of the content to some extent,\n",
    "    # control the API response results, and standardize the output format of the API response.\n",
    "    {\"role\": \"assistant\",\n",
    "     \"content\": \"\"\"\n",
    "                Understood. I will generate the taxonomic key based on the provided morphological matrix. Here is a summary of the steps I will follow:\n",
    "                1. The matrix includes all species and their different states for each character.\n",
    "                2. I will select a character to classify the species into groups and repeat this classification within each subgroup until each group contains only one species, and i'll not ignore any species.\n",
    "                3. I will use information gain to measure how much the uncertainty in the dataset is reduced after using a feature for classification. This helps in selecting features that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "                4. I will select the initial classification character for all species based on the morphological matrix and information gain methods.\n",
    "                5. In the morphological matrix, 'Missing' and 'Not applicable' are considered invalid states. If a character has invalid states for the group being classified, it will be ignored.\n",
    "                6. States are represented by numbers. For example, '1 and 2' means multiple states should be treated as a single state type. (such as '1' and '1 and 2'  is the different state, these are two separate states, when i choose character to based on different state to distinguish the species)\n",
    "                7. I will use information gain to calculate all character and choose the highest information gain result, The higher the Information Gain result, the greater the contribution of the feature to the classification.so i need to make sure the result is Average classification\n",
    "                8. The final result will provide only the initial classification character and the categorization of species based on its state.\n",
    "                9. I will use all the species in their entirety, strictly making sure to categorize all of them! (need to make sure contain all species)\n",
    "                10. Don't need to show how i calculate, only need to show the final result, and please show the final result in #initail character classify result# block, Don't have errors where the state and species don't match\n",
    "                Please provide the morphological matrix data so that I can proceed with the initial classification.\n",
    "            \"\"\"},\n",
    "\n",
    "    # Input the corresponding morphological matrix information for analysis.\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": f\"Here is morphological matrix:{knowledge_graph}\"}\n",
    "]\n",
    "\n",
    "# Set various parameters to control the API response. \n",
    "# Setting the temperature to 0 and limiting max_tokens to save costs and avoid long, redundant outputs.\n",
    "initial_character_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages_initial ,\n",
    "    stop=None,\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    n=1\n",
    ")\n",
    "\n",
    "# Store the API call response results as a file. \n",
    "# (For subsequent distributed API call loops, consider storing in environment variables for continuous calls and modifications).\n",
    "initial_response = initial_character_info.choices[0].message.content\n",
    "\n",
    "# If used as a whole pipeline to transfer the results, ignore this print. \n",
    "# However, for debugging, you can use this print statement to check the response.\n",
    "print(initial_response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T06:31:04.115196Z",
     "start_time": "2024-06-12T06:30:57.970153Z"
    }
   },
   "id": "745a246dd5ad4af",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Character': 'Character1', 'States': {'1': ['Biroia', 'Coccygidium', 'Disophrys', 'Cremnoptoides'], '2': ['Troticus', 'Hypsostypos', 'Cremnops'], '3': ['Gyrochus'], '4': ['Agathis', 'Lytopylus', 'Braunsia', 'Camptothlipsis', 'Therophilus', 'Bassus', 'Earinus', 'Amputostypos', 'Euagathis', 'Aneurobracon']}}\n",
      "[('1', ['Biroia', 'Coccygidium', 'Disophrys', 'Cremnoptoides']), ('2', ['Troticus', 'Hypsostypos', 'Cremnops']), ('3', ['Gyrochus']), ('4', ['Agathis', 'Lytopylus', 'Braunsia', 'Camptothlipsis', 'Therophilus', 'Bassus', 'Earinus', 'Amputostypos', 'Euagathis', 'Aneurobracon'])]\n",
      "('1', ['Biroia', 'Coccygidium', 'Disophrys', 'Cremnoptoides'])\n",
      "('2', ['Troticus', 'Hypsostypos', 'Cremnops'])\n",
      "('3', ['Gyrochus'])\n",
      "('4', ['Agathis', 'Lytopylus', 'Braunsia', 'Camptothlipsis', 'Therophilus', 'Bassus', 'Earinus', 'Amputostypos', 'Euagathis', 'Aneurobracon'])\n"
     ]
    }
   ],
   "source": [
    "def parse_classification_result(result_text):\n",
    "    classification = {\"Character\": None, \"States\": {}}\n",
    "    try:\n",
    "        # Attempt to match the Character\n",
    "        character_match = re.search(r'\"Character\": \"([^\"]+)\"', result_text)\n",
    "        if character_match:\n",
    "            classification[\"Character\"] = character_match.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Character not found in the result text.\")\n",
    "\n",
    "        # Attempt to match each State and the corresponding species\n",
    "        state_sections = re.findall(r'\"(\\d+|[^\"]+)\":\\s*\\[(.*?)\\]', result_text)\n",
    "        if not state_sections:\n",
    "            raise ValueError(\"No states found in the result text.\")\n",
    "\n",
    "        for state, species_block in state_sections:\n",
    "            species_list = re.findall(r'\"([^\"]+)\"', species_block)\n",
    "            if not species_list:\n",
    "                raise ValueError(f\"No species found for state {state}.\")\n",
    "            classification[\"States\"][state] = species_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing classification result: {e}\")\n",
    "        # Decide whether to return an empty classification or raise an exception when an error occurs\n",
    "        raise e  # Or return classification\n",
    "\n",
    "    return classification\n",
    "\n",
    "parsed_initial_classification = parse_classification_result(initial_response)\n",
    "print(parsed_initial_classification)\n",
    "\n",
    "# Function to generate groups from the classification result\n",
    "def generate_groups_from_classification(classification_result):\n",
    "    \"\"\"\n",
    "    Generate groups from classification result.\n",
    "    \n",
    "    :param classification_result: Dictionary containing the classification result\n",
    "    :return: List of tuples, where each tuple contains a state and a list of species\n",
    "    \"\"\"\n",
    "    groups = []\n",
    "    for state, species_list in classification_result[\"States\"].items():\n",
    "        groups.append((state, species_list))\n",
    "    return groups\n",
    "\n",
    "# Generate groups from the parsed initial classification\n",
    "groups = generate_groups_from_classification(parsed_initial_classification)\n",
    "print(groups)\n",
    "print(groups[0])\n",
    "print(groups[1])\n",
    "print(groups[2])\n",
    "print(groups[3])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T07:00:47.777794Z",
     "start_time": "2024-06-12T07:00:47.770233Z"
    }
   },
   "id": "86ea88ee692db823",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# API call function for continued grouping for each subgroup\n",
    "def classify_group(group_species):\n",
    "    # Create a sub-matrix for the group of species\n",
    "    group_matrix = {species: knowledge_graph[species] for species in group_species}\n",
    "    group_matrix_str = json.dumps(group_matrix, ensure_ascii=False)\n",
    "    \n",
    "    # Define the messages for the API call\n",
    "    messages_secondary = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             You are a helpful taxonomist assistant.\n",
    "             You are skilled at calculating the correct information gain to choose the character that best divides species into even groups based on their states.\n",
    "             Based on the selected character, classify the species into different groups according to their states.\n",
    "             For each group with more than two species, continue selecting characters to further classify this group until each group only has one species.\n",
    "             After multiple classifications, determine the final classification levels and record each classifying character and its state.\n",
    "             Finally, generate a taxonomic key.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Generate the nested taxonomic key based on the provided morphological matrix.\n",
    "             The process involves selecting a character to classify the species into groups. Repeat this classification within each subgroup until each group contains only one species.\n",
    "             Information gain measures how much the uncertainty in the dataset is reduced after using a character for classification. It helps in selecting characters that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "             Please select the classification character for these group's species based on the morphological matrix and information gain methods.\n",
    "             In the morphological matrix, 'Missing' and 'Not applicable' are invalid states. If a character has invalid states for the group being classified, it should be ignored.\n",
    "             States are represented by numbers. For example, '1 and 2' means multiple states should be treated as a single state type and this multi-state characterization should not be confused with the single states within it (the state of '3' and '2 and 3' is different state, when you choose the character to based on the state to distinguish need to careful handle). The initial character should have no more than three state types.\n",
    "             You need to calculate the information gain for each character and choose the highest information gain result. The higher the information gain result, the greater the contribution of the feature to the classification.\n",
    "             After selecting the initial classification character and categorizing the species based on its state, repeat the process within each subgroup. For each subgroup, select the character with the highest information gain to further classify the species. Continue this process recursively until each group contains only one species.\n",
    "             Now I will show you the morphological matrix. Please provide the classification character and the categorization of species based on its state. Then, continue to classify each subgroup recursively, showing the chosen character and categorization for each subgroup. Please present the result in a structured format, with each step clearly labeled.\n",
    "             Please don't show how you analyze and calculate, please show me the final result.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Understood. I will generate the nested taxonomic key based on the provided morphological matrix. Here is a summary of the steps I will follow:\n",
    "             1. The matrix includes all species and their different states for each character.\n",
    "             2. I will select a character to classify the species into groups and repeat this classification within each subgroup until each group contains only one species.\n",
    "             3. I will use information gain to measure how much the uncertainty in the dataset is reduced after using a feature for classification. This helps in selecting features that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "             4. I will select the classification character for the group's species based on the morphological matrix and information gain methods.\n",
    "             5. In the morphological matrix, 'Missing' and 'Not applicable' are considered invalid states. If a character has invalid states for the group being classified, it will be ignored.\n",
    "             6. States are represented by numbers. For example, '2 and 3' means multiple states should be treated as a single state type, and this multi-state characterization should not be confused with the individual states (like '2', '3') within it (such as '3' and '2 and 3' are different states, these are two separate states, when I choose a character based on different states to distinguish the species). The classification character should have no more than three state types.\n",
    "             7. I will use information gain to calculate all characters and choose the highest information gain result. The higher the information gain result, the greater the contribution of the feature to the classification.\n",
    "             8. The final result will provide only the initial classification character and the categorization of species based on its state.\n",
    "             9. Don't need to show how the process about choosing, only need to show the final result as a nested structure, and I will store the result in #character classify result# block.\n",
    "             Please provide the group morphological matrix data so that I can proceed with the classification.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the group information need to be classify and include the morphological matrix {group_matrix_str}\"}\n",
    "    ]\n",
    "    \n",
    "    # Make the API call to classify the group\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages_secondary,\n",
    "        stop=None,\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "        n=1\n",
    "    )\n",
    "    result_secondary = response.choices[0].message.content\n",
    "    # print(f\"API response for group {group_species}: {result}\")\n",
    "    \n",
    "    # Define messages for formatting the response to JSON\n",
    "    messages_JSON = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             You are a helpful JSON format converter.\n",
    "             You can express the nested structure as a JSON result based on the corresponding content.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Please format the classification result as follows:\n",
    "             ```\n",
    "             # Final taxonomic key result JSON format #\n",
    "             {\n",
    "                 \"Character\": \"CharacterX\",\n",
    "                 \"States\": {\n",
    "                     \"1\": [\"speciesA\"],\n",
    "                     \"2\": {\n",
    "                         \"Character\": \"CharacterY\",\n",
    "                         \"States\": {\n",
    "                             \"1\": [\"speciesB\"],\n",
    "                             \"2\": [\"speciesC\"]\n",
    "                         }\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "             ```\n",
    "             Ensure that the response follows this format exactly.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Understood. I'll convert the nested structure you gave me into JSON format and store it in # final result #.\n",
    "             Please provide what you need to convert the format.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here are the taxonomic results for the nested schema representation {result_secondary}\"}\n",
    "    ]\n",
    "    \n",
    "    # Make the API call to format the response as JSON\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages_JSON,\n",
    "        stop=None,\n",
    "        temperature=0,\n",
    "        max_tokens=1500,\n",
    "        n=1\n",
    "    )\n",
    "    json_result = response.choices[0].message.content\n",
    "    print(json_result)\n",
    "    return json_result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T06:59:03.540003Z",
     "start_time": "2024-06-12T06:59:03.533075Z"
    }
   },
   "id": "c0a264c44051420",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to clean and extract JSON string\n",
    "def extract_json_string(json_string):\n",
    "    # Find the positions of the start and end of the JSON object\n",
    "    start = json_string.find('{')\n",
    "    end = json_string.rfind('}') + 1\n",
    "    \n",
    "    # If both start and end positions are valid, extract and return the JSON string\n",
    "    if start != -1 and end != -1:\n",
    "        cleaned_string = json_string[start:end]\n",
    "        return cleaned_string.strip()\n",
    "    \n",
    "    # If positions are not valid, return an empty string\n",
    "    return \"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T06:59:07.216751Z",
     "start_time": "2024-06-12T06:59:07.213301Z"
    }
   },
   "id": "6bcc77085713e069",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def recursive_classification(groups, final_classification, classification_results, depth=0, max_depth=10):\n",
    "    \"\"\"\n",
    "    Recursive classification function to process groups and store results.\n",
    "    :param groups: Groups to be processed\n",
    "    :param final_classification: Final classification result\n",
    "    :param classification_results: Classification results\n",
    "    :param depth: Current recursion depth\n",
    "    :param max_depth: Maximum recursion depth\n",
    "    :return: Final classification result\n",
    "    \"\"\"\n",
    "    # Continue looping while the groups list is not empty\n",
    "    # Initialize state and current_group for error handling\n",
    "    state, current_group = None, []\n",
    "    while groups:\n",
    "        try:\n",
    "            # Pop the first group from the list, getting the state and current group of species\n",
    "            state, current_group = groups.pop(0)\n",
    "            print(f\"Processing group with state: {state}, species: {current_group}, at depth: {depth}\")\n",
    "\n",
    "            # If the current group has only one species, add it to the final classification\n",
    "            if len(current_group) == 1:\n",
    "                final_classification[current_group[0]] = current_group\n",
    "            # If the current recursion depth has reached the maximum depth, stop further classification\n",
    "            elif depth >= max_depth:\n",
    "                print(f\"Reached max depth {max_depth}. Stopping further classification for group: {current_group}\")\n",
    "                final_classification[state] = current_group\n",
    "            else:\n",
    "                # Call the classify_group function to classify the current group\n",
    "                classification_result = classify_group(current_group)\n",
    "                # Clean the API classification result to extract the JSON string\n",
    "                cleaned_classification_result = extract_json_string(classification_result)  \n",
    "                # Store the classification result in classification_results\n",
    "                classification_results[state] = cleaned_classification_result\n",
    "\n",
    "                # Parse the classification result, create new subgroups, and add them to groups for further classification\n",
    "                new_groups = []\n",
    "                parsed_result = parse_classification_result(classification_result)\n",
    "                for new_state, new_species_list in parsed_result[\"States\"].items():\n",
    "                    new_groups.append((new_state, new_species_list))\n",
    "\n",
    "                # Recursively call itself to process new subgroups, increasing the recursion depth\n",
    "                recursive_classification(new_groups, final_classification, classification_results, depth + 1, max_depth)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch exceptions and print error messages\n",
    "            print(f\"Error processing group with state: {state}, species: {current_group}, at depth: {depth}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            raise e\n",
    "\n",
    "    return final_classification"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T06:31:52.458793Z",
     "start_time": "2024-06-12T06:31:52.453072Z"
    }
   },
   "id": "718e25487a7fba3d",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial groups: [('1', ['Biroia', 'Coccygidium', 'Disophrys', 'Cremnoptoides']), ('2', ['Troticus', 'Hypsostypos', 'Cremnops']), ('3', ['Gyrochus']), ('4', ['Agathis', 'Lytopylus', 'Braunsia', 'Camptothlipsis', 'Therophilus', 'Bassus', 'Earinus', 'Amputostypos', 'Euagathis', 'Aneurobracon'])]\n",
      "Initial final_classification: {}\n",
      "Initial classification_results: {}\n",
      "Processing group with state: 1, species: ['Biroia', 'Coccygidium', 'Disophrys', 'Cremnoptoides'], at depth: 0\n",
      "```json\n",
      "{\n",
      "    \"Character\": \"Character 5\",\n",
      "    \"States\": {\n",
      "        \"1\": [\"Coccygidium\"],\n",
      "        \"2\": {\n",
      "            \"Character\": \"Character 13\",\n",
      "            \"States\": {\n",
      "                \"1\": [\"Cremnoptoides\"],\n",
      "                \"2\": {\n",
      "                    \"Character\": \"Character 9\",\n",
      "                    \"States\": {\n",
      "                        \"1\": [\"Biroia\"],\n",
      "                        \"1 and 2\": [\"Disophrys\"]\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "Processing group with state: 1, species: ['Biroia'], at depth: 1\n",
      "Processing group with state: 1 and 2, species: ['Disophrys'], at depth: 1\n",
      "Processing group with state: 2, species: ['Troticus', 'Hypsostypos', 'Cremnops'], at depth: 0\n",
      "Here is the nested taxonomic key in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"Character\": \"Character 1\",\n",
      "    \"States\": {\n",
      "        \"1 and 2\": [\"Cremnops\"],\n",
      "        \"2\": {\n",
      "            \"Character\": \"Character 9\",\n",
      "            \"States\": {\n",
      "                \"1\": [\"Hypsostypos\"],\n",
      "                \"2\": [\"Troticus\"]\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "This JSON structure represents the classification of species based on the provided characters and their states.\n",
      "Processing group with state: 1 and 2, species: ['Cremnops'], at depth: 1\n",
      "Processing group with state: 1, species: ['Hypsostypos'], at depth: 1\n",
      "Processing group with state: 2, species: ['Troticus'], at depth: 1\n",
      "Processing group with state: 3, species: ['Gyrochus'], at depth: 0\n",
      "Processing group with state: 4, species: ['Agathis', 'Lytopylus', 'Braunsia', 'Camptothlipsis', 'Therophilus', 'Bassus', 'Earinus', 'Amputostypos', 'Euagathis', 'Aneurobracon'], at depth: 0\n",
      "```json\n",
      "{\n",
      "    \"Character\": \"Character2\",\n",
      "    \"States\": {\n",
      "        \"1\": [\"Earinus\"],\n",
      "        \"2\": {\n",
      "            \"Character\": \"Character3\",\n",
      "            \"States\": {\n",
      "                \"2\": {\n",
      "                    \"Character\": \"Character4\",\n",
      "                    \"States\": {\n",
      "                        \"1 and 2\": [\"Lytopylus\"],\n",
      "                        \"2\": [\"Therophilus\"]\n",
      "                    }\n",
      "                },\n",
      "                \"3\": [\"Bassus\"]\n",
      "            }\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"Character\": \"Character3\",\n",
      "            \"States\": {\n",
      "                \"2 and 3\": [\"Aneurobracon\"],\n",
      "                \"2\": [\"Camptothlipsis\"]\n",
      "            }\n",
      "        },\n",
      "        \"1 and 2\": {\n",
      "            \"Character\": \"Character3\",\n",
      "            \"States\": {\n",
      "                \"1\": {\n",
      "                    \"Character\": \"Character10\",\n",
      "                    \"States\": {\n",
      "                        \"1\": [\"Amputostypos\", \"Euagathis\"]\n",
      "                    }\n",
      "                },\n",
      "                \"2\": {\n",
      "                    \"Character\": \"Character9\",\n",
      "                    \"States\": {\n",
      "                        \"1\": [\"Agathis\"],\n",
      "                        \"2\": [\"Braunsia\"]\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "Processing group with state: 1, species: ['Agathis'], at depth: 1\n",
      "Processing group with state: 1 and 2, species: ['Lytopylus'], at depth: 1\n",
      "Processing group with state: 2, species: ['Braunsia'], at depth: 1\n",
      "Processing group with state: 3, species: ['Bassus'], at depth: 1\n",
      "Processing group with state: 2 and 3, species: ['Aneurobracon'], at depth: 1\n",
      "Final Classification:\n",
      "{\n",
      "  \"Biroia\": [\n",
      "    \"Biroia\"\n",
      "  ],\n",
      "  \"Disophrys\": [\n",
      "    \"Disophrys\"\n",
      "  ],\n",
      "  \"Cremnops\": [\n",
      "    \"Cremnops\"\n",
      "  ],\n",
      "  \"Hypsostypos\": [\n",
      "    \"Hypsostypos\"\n",
      "  ],\n",
      "  \"Troticus\": [\n",
      "    \"Troticus\"\n",
      "  ],\n",
      "  \"Gyrochus\": [\n",
      "    \"Gyrochus\"\n",
      "  ],\n",
      "  \"Agathis\": [\n",
      "    \"Agathis\"\n",
      "  ],\n",
      "  \"Lytopylus\": [\n",
      "    \"Lytopylus\"\n",
      "  ],\n",
      "  \"Braunsia\": [\n",
      "    \"Braunsia\"\n",
      "  ],\n",
      "  \"Bassus\": [\n",
      "    \"Bassus\"\n",
      "  ],\n",
      "  \"Aneurobracon\": [\n",
      "    \"Aneurobracon\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "Classification Results:\n",
      "{'1': '{\\n    \"Character\": \"Character 5\",\\n    \"States\": {\\n        \"1\": [\"Coccygidium\"],\\n        \"2\": {\\n            \"Character\": \"Character 13\",\\n            \"States\": {\\n                \"1\": [\"Cremnoptoides\"],\\n                \"2\": {\\n                    \"Character\": \"Character 9\",\\n                    \"States\": {\\n                        \"1\": [\"Biroia\"],\\n                        \"1 and 2\": [\"Disophrys\"]\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}', '2': '{\\n    \"Character\": \"Character 1\",\\n    \"States\": {\\n        \"1 and 2\": [\"Cremnops\"],\\n        \"2\": {\\n            \"Character\": \"Character 9\",\\n            \"States\": {\\n                \"1\": [\"Hypsostypos\"],\\n                \"2\": [\"Troticus\"]\\n            }\\n        }\\n    }\\n}', '4': '{\\n    \"Character\": \"Character2\",\\n    \"States\": {\\n        \"1\": [\"Earinus\"],\\n        \"2\": {\\n            \"Character\": \"Character3\",\\n            \"States\": {\\n                \"2\": {\\n                    \"Character\": \"Character4\",\\n                    \"States\": {\\n                        \"1 and 2\": [\"Lytopylus\"],\\n                        \"2\": [\"Therophilus\"]\\n                    }\\n                },\\n                \"3\": [\"Bassus\"]\\n            }\\n        },\\n        \"3\": {\\n            \"Character\": \"Character3\",\\n            \"States\": {\\n                \"2 and 3\": [\"Aneurobracon\"],\\n                \"2\": [\"Camptothlipsis\"]\\n            }\\n        },\\n        \"1 and 2\": {\\n            \"Character\": \"Character3\",\\n            \"States\": {\\n                \"1\": {\\n                    \"Character\": \"Character10\",\\n                    \"States\": {\\n                        \"1\": [\"Amputostypos\", \"Euagathis\"]\\n                    }\\n                },\\n                \"2\": {\\n                    \"Character\": \"Character9\",\\n                    \"States\": {\\n                        \"1\": [\"Agathis\"],\\n                        \"2\": [\"Braunsia\"]\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}'}\n"
     ]
    }
   ],
   "source": [
    "# Assume the variables have been initialized\n",
    "max_depth =  5  # Can be adjusted based on the hierarchical structure of input data and application requirements\n",
    "# here is the initial character level is about species number need to classify\n",
    "\n",
    "# Dictionary to store the final classification where each species is classified individually\n",
    "final_classification = {}\n",
    "\n",
    "# Dictionary to store the API classification results for each state\n",
    "classification_results = {}\n",
    "\n",
    "# Print the initial state of groups and dictionaries for debugging purposes\n",
    "print(\"Initial groups:\", groups)\n",
    "print(\"Initial final_classification:\", final_classification)\n",
    "print(\"Initial classification_results:\", classification_results)\n",
    "\n",
    "# Call the recursive_classification function to process the groups and store the results\n",
    "final_classification = recursive_classification(groups, final_classification, classification_results, depth=0, max_depth=max_depth)\n",
    "\n",
    "# Print the final classification results\n",
    "print(\"Final Classification:\")\n",
    "print(json.dumps(final_classification, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Print the classification results from the API calls\n",
    "print(\"\\nClassification Results:\")\n",
    "print(classification_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T06:59:51.492079Z",
     "start_time": "2024-06-12T06:59:17.559441Z"
    }
   },
   "id": "11d47ae207d91371",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', ['Biroia', 'Coccygidium', 'Disophrys', 'Cremnoptoides']), ('2', ['Troticus', 'Hypsostypos', 'Cremnops']), ('3', ['Gyrochus']), ('4', ['Agathis', 'Lytopylus', 'Braunsia', 'Camptothlipsis', 'Therophilus', 'Bassus', 'Earinus', 'Amputostypos', 'Euagathis', 'Aneurobracon'])]\n",
      "<class 'list'>\n",
      "{'1': '{\\n    \"Character\": \"Character 5\",\\n    \"States\": {\\n        \"1\": [\"Coccygidium\"],\\n        \"2\": {\\n            \"Character\": \"Character 13\",\\n            \"States\": {\\n                \"1\": [\"Cremnoptoides\"],\\n                \"2\": {\\n                    \"Character\": \"Character 9\",\\n                    \"States\": {\\n                        \"1\": [\"Biroia\"],\\n                        \"1 and 2\": [\"Disophrys\"]\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}', '2': '{\\n    \"Character\": \"Character 1\",\\n    \"States\": {\\n        \"1 and 2\": [\"Cremnops\"],\\n        \"2\": {\\n            \"Character\": \"Character 9\",\\n            \"States\": {\\n                \"1\": [\"Hypsostypos\"],\\n                \"2\": [\"Troticus\"]\\n            }\\n        }\\n    }\\n}', '4': '{\\n    \"Character\": \"Character2\",\\n    \"States\": {\\n        \"1\": [\"Earinus\"],\\n        \"2\": {\\n            \"Character\": \"Character3\",\\n            \"States\": {\\n                \"2\": {\\n                    \"Character\": \"Character4\",\\n                    \"States\": {\\n                        \"1 and 2\": [\"Lytopylus\"],\\n                        \"2\": [\"Therophilus\"]\\n                    }\\n                },\\n                \"3\": [\"Bassus\"]\\n            }\\n        },\\n        \"3\": {\\n            \"Character\": \"Character3\",\\n            \"States\": {\\n                \"2 and 3\": [\"Aneurobracon\"],\\n                \"2\": [\"Camptothlipsis\"]\\n            }\\n        },\\n        \"1 and 2\": {\\n            \"Character\": \"Character3\",\\n            \"States\": {\\n                \"1\": {\\n                    \"Character\": \"Character10\",\\n                    \"States\": {\\n                        \"1\": [\"Amputostypos\", \"Euagathis\"]\\n                    }\\n                },\\n                \"2\": {\\n                    \"Character\": \"Character9\",\\n                    \"States\": {\\n                        \"1\": [\"Agathis\"],\\n                        \"2\": [\"Braunsia\"]\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(groups)\n",
    "print(type(groups))\n",
    "print(classification_results)\n",
    "print(type(classification_results))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T07:00:52.997554Z",
     "start_time": "2024-06-12T07:00:52.993365Z"
    }
   },
   "id": "266b0a33a45c601c",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_paths(node, path=None):\n",
    "    if path is None:\n",
    "        path = {}\n",
    "\n",
    "    if 'Character' in node and 'States' in node:\n",
    "        current_character = node['Character'].replace(\" \", \"\").strip()\n",
    "        for state, value in node['States'].items():\n",
    "            new_path = path.copy()\n",
    "            new_path[current_character] = state\n",
    "            if isinstance(value, dict):\n",
    "                yield from extract_paths(value, new_path)\n",
    "            else:\n",
    "                for species in value:\n",
    "                    yield species, new_path\n",
    "\n",
    "# 处理每个分类结果并提取路径\n",
    "final_results = {}\n",
    "\n",
    "for key, json_str in classification_results.items():\n",
    "    classification_data = json.loads(json_str)\n",
    "    species_paths = list(extract_paths(classification_data))\n",
    "\n",
    "    formatted_results = {}\n",
    "    for species, path in species_paths:\n",
    "        formatted_results[species] = {\"Characteristics\": path}\n",
    "    \n",
    "    final_results[key] = formatted_results\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T07:00:57.244968Z",
     "start_time": "2024-06-12T07:00:57.241140Z"
    }
   },
   "id": "9c7c1139650cf60d",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_state_match(state, correct_state):\n",
    "    if correct_state is None:\n",
    "        return False\n",
    "    if \" and \" in correct_state:\n",
    "        correct_states = correct_state.split(\" and \")\n",
    "        return all(sub_state in correct_states for sub_state in state.split(\" and \"))\n",
    "    return state == correct_state\n",
    "\n",
    "# Validate classification results and log errors\n",
    "def validate_results(final_results, knowledge_graph):\n",
    "    errors = []\n",
    "    for key, results in final_results.items():\n",
    "        for species, data in results.items():\n",
    "            if species in knowledge_graph:\n",
    "                mismatch = False\n",
    "                incorrect_character_states = {}\n",
    "                for character, state in data[\"Characteristics\"].items():\n",
    "                    character = character.replace(\" \", \"\").strip()\n",
    "                    correct_state = knowledge_graph[species][\"Characteristics\"].get(character)\n",
    "                    if correct_state is None or not check_state_match(state, correct_state):\n",
    "                        mismatch = True\n",
    "                        incorrect_character_states[character] = {\"error_state\": state, \"correct_state\": correct_state}\n",
    "                if mismatch:\n",
    "                    errors.append({\n",
    "                        \"species\": species,\n",
    "                        \"key\": key,\n",
    "                        \"error\": \"Mismatch\",\n",
    "                        \"error_result\": incorrect_character_states,\n",
    "                        \"correct_result\": {character: knowledge_graph[species][\"Characteristics\"].get(character) for character in incorrect_character_states}\n",
    "                    })\n",
    "            else:\n",
    "                errors.append({\n",
    "                    \"species\": species,\n",
    "                    \"key\": key,\n",
    "                    \"error\": \"Species not found in knowledge graph\",\n",
    "                    \"error_result\": data[\"Characteristics\"]\n",
    "                })\n",
    "    return errors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T07:00:59.296562Z",
     "start_time": "2024-06-12T07:00:59.292490Z"
    }
   },
   "id": "6cab39ffea0bbc52",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def correct_classification(errors, classification_results, knowledge_graph):\n",
    "    for error in errors:\n",
    "        key = error['key']\n",
    "        \n",
    "        species_list = []\n",
    "        for group in groups:\n",
    "            if 'States' in group and key in group['States']:\n",
    "                species_list = group['States'][key]\n",
    "                break\n",
    "        if not species_list:\n",
    "            print(f\"Key {key} not found in any group['States']\")\n",
    "            continue\n",
    "        print(f\"Processing species list for state '{key}': {species_list}\")\n",
    "        \n",
    "        group_matrix = {s: knowledge_graph[s] for s in species_list}\n",
    "        group_matrix_str = json.dumps(group_matrix, ensure_ascii=False) \n",
    "        \n",
    "        messages2 = [\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": \"\"\"\n",
    "             You are a helpful taxonomist assistant.\n",
    "             You are skilled at calculating the correct information gain to choose the character that best divides species into even groups based on their states.\n",
    "             Based on the selected character, classify the species into different groups according to their states.\n",
    "             For each group with more than two species, continue selecting characters to further classify this group until each group only has one species.\n",
    "             After multiple classifications, determine the final classification levels and record each classifying character and its state.\n",
    "             Finally, generate a taxonomic key.\n",
    "             You are able to avoid the same error in your results based on the corrected results previously passed to you\n",
    "             \"\"\"},\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": \"\"\"\n",
    "             Generate the nested taxonomic key based on the provided morphological matrix.\n",
    "             The process involves selecting a character to classify the species into groups. Repeat this classification within each subgroup until each group contains only one species.\n",
    "             Information gain measures how much the uncertainty in the dataset is reduced after using a character for classification. It helps in selecting characters that minimize the entropy of the subset after classification, leading to better classification results.\n",
    "             Please select the classification character for these group's species based on the morphological matrix and information gain methods.\n",
    "             In the morphological matrix, 'Missing' and 'Not applicable' are invalid states. If a character has invalid states for the group being classified, it should be ignored.\n",
    "             States are represented by numbers. For example, '1 and 2' means multiple states should be treated as a single state type and this multi-state characterization should not be confused with the single states within it (the state of '3' and '2 and 3' is different state, when you choose the character to based on the state to distinguish need to careful handle). The initial character should have no more than three state types.\n",
    "             You need to calculate the information gain for each character and choose the highest information gain result. The higher the information gain result, the greater the contribution of the feature to the classification.\n",
    "             After selecting the initial classification character and categorizing the species based on its state, repeat the process within each subgroup. For each subgroup, select the character with the highest information gain to further classify the species. Continue this process recursively until each group contains only one species.\n",
    "             Now I will show you the morphological matrix. Please provide the classification character and the categorization of species based on its state. Then, continue to classify each subgroup recursively, showing the chosen character and categorization for each subgroup. Please present the result in a structured format, with each step clearly labeled.\n",
    "             Please don't show how you analyze and calculate, please show me the final result.\n",
    "             \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            This is the result of the error you generated in the previous API call. \n",
    "            In this file I have provided you with the CORRECT result. \n",
    "            Please strictly adhere to the use of the correct species feature status message!{error}\n",
    "            \"\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"\"\"\n",
    "            I will strictly use the correct species feature state information for evaluation, \n",
    "            while I will avoid using these incorrect feature state information that appeared previously in the classification results\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Here is the group information need to be classify and include the morphological matrix {group_matrix_str}\"}\n",
    "        ]\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages2,\n",
    "            stop=None,\n",
    "            temperature=0,\n",
    "            max_tokens=1000,\n",
    "            n=1\n",
    "        )\n",
    "        corrected_result = response.choices[0].message.content\n",
    "        \n",
    "        messages_JSON = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             You are a helpful JSON format converter.\n",
    "             You can express the nested structure as a JSON result based on the corresponding content.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"system\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Please format the classification result as follows:\n",
    "             ```\n",
    "             # Final taxonomic key result JSON format #\n",
    "             {\n",
    "                 \"Character\": \"CharacterX\",\n",
    "                 \"States\": {\n",
    "                     \"1\": [\"speciesA\"],\n",
    "                     \"2\": {\n",
    "                         \"Character\": \"CharacterY\",\n",
    "                         \"States\": {\n",
    "                             \"1\": [\"speciesB\"],\n",
    "                             \"2\": [\"speciesC\"]\n",
    "                         }\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "             ```\n",
    "             Ensure that the response follows this format exactly.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\":\n",
    "             \"\"\"\n",
    "             Understood. I'll convert the nested structure you gave me into JSON format and store it in # final result #.\n",
    "             Please provide what you need to convert the format.\n",
    "             \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here are the taxonomic results for the nested schema representation {corrected_result}\"}\n",
    "        ]\n",
    "    \n",
    "        # Make the API call to format the response as JSON\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages_JSON,\n",
    "            stop=None,\n",
    "            temperature=0,\n",
    "            max_tokens=1500,\n",
    "            n=1\n",
    "        )\n",
    "        json_result = response.choices[0].message.content\n",
    "        json_cleaned_result = extract_json_string(json_result)\n",
    "        print(json_cleaned_result)\n",
    "        classification_results[key] = json_cleaned_result\n",
    "        return classification_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T07:01:02.471035Z",
     "start_time": "2024-06-12T07:01:02.464814Z"
    }
   },
   "id": "e895eee68fca094b",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final classification results have been saved to 'final_classification.json'.\n",
      "{\n",
      "    \"1\": {\n",
      "        \"Coccygidium\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character5\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Cremnoptoides\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character5\": \"2\",\n",
      "                \"Character13\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Biroia\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character5\": \"2\",\n",
      "                \"Character13\": \"2\",\n",
      "                \"Character9\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Disophrys\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character5\": \"2\",\n",
      "                \"Character13\": \"2\",\n",
      "                \"Character9\": \"1 and 2\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"Cremnops\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character1\": \"1 and 2\"\n",
      "            }\n",
      "        },\n",
      "        \"Hypsostypos\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character1\": \"2\",\n",
      "                \"Character9\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Troticus\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character1\": \"2\",\n",
      "                \"Character9\": \"2\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"Earinus\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Lytopylus\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"2\",\n",
      "                \"Character3\": \"2\",\n",
      "                \"Character4\": \"1 and 2\"\n",
      "            }\n",
      "        },\n",
      "        \"Therophilus\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"2\",\n",
      "                \"Character3\": \"2\",\n",
      "                \"Character4\": \"2\"\n",
      "            }\n",
      "        },\n",
      "        \"Bassus\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"2\",\n",
      "                \"Character3\": \"3\"\n",
      "            }\n",
      "        },\n",
      "        \"Aneurobracon\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"3\",\n",
      "                \"Character3\": \"2 and 3\"\n",
      "            }\n",
      "        },\n",
      "        \"Camptothlipsis\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"3\",\n",
      "                \"Character3\": \"2\"\n",
      "            }\n",
      "        },\n",
      "        \"Amputostypos\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"1 and 2\",\n",
      "                \"Character3\": \"1\",\n",
      "                \"Character10\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Euagathis\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"1 and 2\",\n",
      "                \"Character3\": \"1\",\n",
      "                \"Character10\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Agathis\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"1 and 2\",\n",
      "                \"Character3\": \"2\",\n",
      "                \"Character9\": \"1\"\n",
      "            }\n",
      "        },\n",
      "        \"Braunsia\": {\n",
      "            \"Characteristics\": {\n",
      "                \"Character2\": \"1 and 2\",\n",
      "                \"Character3\": \"2\",\n",
      "                \"Character9\": \"2\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Cycle checks and corrections\n",
    "errors = validate_results(final_results, knowledge_graph)\n",
    "# Purpose: Enter a loop until all errors have been fixed.\n",
    "# Function: Executes the code inside the loop when the errors list is not empty.\n",
    "while errors:\n",
    "    # Fix current categorization errors. (based on the API )\n",
    "    classification_results = correct_classification(errors, classification_results, knowledge_graph)\n",
    "    # Purpose: To reset the final_results dictionary to store the corrected categorization results.\n",
    "    final_results = {}\n",
    "    # Iterate over the corrected classification results and extract species classification paths.\n",
    "    for key, json_str in classification_results.items():\n",
    "        classification_data = json.loads(json_str)\n",
    "        species_paths = list(extract_paths(classification_data))\n",
    "        # Purpose: Format the extracted classification paths and store them in the formatted_results dictionary.\n",
    "        formatted_results = {}\n",
    "        for species, path in species_paths:\n",
    "            formatted_results[species] = {\"Characteristics\": path}\n",
    "        # Purpose: Add the formatted classification results to final_results.\n",
    "        final_results[key] = formatted_results\n",
    "    # Purpose: Re-validate the corrected classification results and log any remaining errors.\n",
    "    # Function: Call the validate_results function, passing in the updated final_results and knowledge_graph and returning a new list of errors. If there are no errors, then errors is empty and the loop ends.\n",
    "    errors = validate_results(final_results, knowledge_graph)\n",
    "\n",
    "# Save the final classification results\n",
    "with open('final_classification.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=4)\n",
    "\n",
    "print(\"Final classification results have been saved to 'final_classification.json'.\")\n",
    "print(json.dumps(final_results, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T07:01:07.995590Z",
     "start_time": "2024-06-12T07:01:07.990979Z"
    }
   },
   "id": "703e027a845beefd",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Character1:**\n",
      "   - State \"1\":\n",
      "    1. **Character 5:**\n",
      "       - State \"1\": Coccygidium\n",
      "       - State \"2\":\n",
      "        1. **Character 13:**\n",
      "           - State \"1\": Cremnoptoides\n",
      "           - State \"2\":\n",
      "            1. **Character 9:**\n",
      "               - State \"1\": Biroia\n",
      "               - State \"1 and 2\": Disophrys\n",
      "   - State \"2\":\n",
      "    1. **Character 1:**\n",
      "       - State \"1 and 2\": Cremnops\n",
      "       - State \"2\":\n",
      "        1. **Character 9:**\n",
      "           - State \"1\": Hypsostypos\n",
      "           - State \"2\": Troticus\n",
      "   - State \"3\": Gyrochus\n",
      "   - State \"4\":\n",
      "    1. **Character2:**\n",
      "       - State \"1\": Earinus\n",
      "       - State \"2\":\n",
      "        1. **Character3:**\n",
      "           - State \"2\":\n",
      "            1. **Character4:**\n",
      "               - State \"1 and 2\": Lytopylus\n",
      "               - State \"2\": Therophilus\n",
      "           - State \"3\": Bassus\n",
      "       - State \"3\":\n",
      "        1. **Character3:**\n",
      "           - State \"2 and 3\": Aneurobracon\n",
      "           - State \"2\": Camptothlipsis\n",
      "       - State \"1 and 2\":\n",
      "        1. **Character3:**\n",
      "           - State \"1\":\n",
      "            1. **Character10:**\n",
      "               - State \"1\": Amputostypos, Euagathis\n",
      "           - State \"2\":\n",
      "            1. **Character9:**\n",
      "               - State \"1\": Agathis\n",
      "               - State \"2\": Braunsia\n",
      "\n",
      "Final Result JSON:\n"
     ]
    }
   ],
   "source": [
    "# Example initial result\n",
    "initial_result = parsed_initial_classification\n",
    "\n",
    "# Parse the API response JSON strings\n",
    "parsed_classification_results = {key: json.loads(value) for key, value in classification_results.items()}\n",
    "\n",
    "# Function to combine the initial and secondary classification results\n",
    "def combine_results(initial, secondary, state_key):\n",
    "    if not secondary:\n",
    "        return\n",
    "\n",
    "    initial_states = initial[\"States\"].get(state_key)\n",
    "    if initial_states is None:\n",
    "        initial[\"States\"][state_key] = secondary\n",
    "        return\n",
    "\n",
    "    if isinstance(initial_states, list):\n",
    "        if isinstance(secondary, list):\n",
    "            initial[\"States\"][state_key] = list(set(initial_states + secondary))  # Merge two lists and remove duplicates\n",
    "        else:\n",
    "            initial[\"States\"][state_key] = secondary\n",
    "    elif isinstance(initial_states, dict):\n",
    "        if isinstance(secondary, dict):\n",
    "            for key, value in secondary[\"States\"].items():\n",
    "                if key not in initial_states:\n",
    "                    initial_states[key] = value\n",
    "                else:\n",
    "                    combine_results(initial_states, value, key)\n",
    "        else:\n",
    "            raise ValueError(f\"Conflicting types for key {state_key}: {type(initial_states)} vs {type(secondary)}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected type for initial states: {type(initial_states)}\")\n",
    "\n",
    "# Dynamically combine all secondary classification results\n",
    "for state_key, secondary in parsed_classification_results.items():\n",
    "    combine_results(initial_result, secondary, state_key)\n",
    "\n",
    "# Function to display the final classification result\n",
    "def display_classification(result, indent=0):\n",
    "    indent_space = \" \" * indent\n",
    "    character = result.get(\"Character\")\n",
    "    states = result.get(\"States\")\n",
    "\n",
    "    classification = {}\n",
    "    if character and states:\n",
    "        classification[\"Character\"] = character\n",
    "        classification[\"States\"] = {}\n",
    "        print(f\"{indent_space}1. **{character}:**\")\n",
    "        for state, species in states.items():\n",
    "            if isinstance(species, list):\n",
    "                print(f\"{indent_space}   - State \\\"{state}\\\": {', '.join(species)}\")\n",
    "                classification[\"States\"][state] = species\n",
    "            elif isinstance(species, dict):\n",
    "                print(f\"{indent_space}   - State \\\"{state}\\\":\")\n",
    "                classification[\"States\"][state] = display_classification(species, indent + 4)\n",
    "    return classification\n",
    "\n",
    "# Display the final classification result\n",
    "final_result = display_classification(initial_result)\n",
    "print(\"\\nFinal Result JSON:\")\n",
    "# print(json.dumps(final_result, indent=2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T07:01:17.712925Z",
     "start_time": "2024-06-12T07:01:17.706141Z"
    }
   },
   "id": "fe91254cdf2ef13d",
   "execution_count": 83
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
